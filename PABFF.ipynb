{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIf4KtGOWHoC"
   },
   "source": [
    "# Artist Collaboration Network Analysis (2017~2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "eFWEmIC_VGmW",
    "outputId": "4dcefa03-b264-4962-df7c-f7753bcb8497"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import community as community_louvain\n",
    "import numpy as np\n",
    "\n",
    "# File paths and column names by year\n",
    "files = {\n",
    "    2017: '/content/global-artist_network-2017.csv',\n",
    "    2018: '/content/global-artist_network-2018.csv',\n",
    "    2019: '/content/global-artist_network-2019.csv'\n",
    "}\n",
    "\n",
    "# Store graphs, partitions, and degrees by year\n",
    "graphs = {}\n",
    "partitions = {}\n",
    "degrees = {}\n",
    "\n",
    "for year, path in files.items():\n",
    "    # 1. Read file (auto-detect delimiter)\n",
    "    try:\n",
    "        df = pd.read_csv(path, sep='\\t', engine='python')\n",
    "        edge_cols = ['artist_1', 'artist_2', 'count']\n",
    "    except Exception:\n",
    "        df = pd.read_csv(path, sep='\\s+', engine='python')\n",
    "        edge_cols = ['artist1', 'artist2', 'count']\n",
    "    df.columns = df.columns.str.strip()\n",
    "    edges = df[edge_cols].dropna()\n",
    "    edges['count'] = pd.to_numeric(edges['count'], errors='coerce').fillna(1).astype(int)\n",
    "    # 2. Create graph\n",
    "    G = nx.Graph()\n",
    "    for _, row in edges.iterrows():\n",
    "        G.add_edge(row[edge_cols[0]], row[edge_cols[1]], weight=row['count'])\n",
    "    # 3. Community detection\n",
    "    partition = community_louvain.best_partition(G, weight='weight')\n",
    "    deg = dict(G.degree(weight='weight'))\n",
    "    graphs[year] = G\n",
    "    partitions[year] = partition\n",
    "    degrees[year] = deg\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "cmap = plt.get_cmap('tab20')\n",
    "\n",
    "for idx, year in enumerate(sorted(files.keys())):\n",
    "    G = graphs[year]\n",
    "    partition = partitions[year]\n",
    "    deg = degrees[year]\n",
    "    communities = [partition[n] for n in G.nodes()]\n",
    "    colors = [cmap(c % 20) for c in communities]\n",
    "    node_sizes = [deg[n]*5 for n in G.nodes()]\n",
    "    # Fix layout with the same seed\n",
    "    pos = nx.spring_layout(G, k=0.15, seed=42)\n",
    "    ax = axes[idx]\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=colors, node_size=node_sizes, alpha=0.7, ax=ax)\n",
    "    nx.draw_networkx_edges(G, pos, width=[G[u][v]['weight']*0.2 for u, v in G.edges()], alpha=0.2, ax=ax)\n",
    "    ax.set_title(f'{year} Artist Collaboration Network')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('2017-2019 Artist Collaboration Network Comparison (Color=Community, Size=Degree)', fontsize=18)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 885
    },
    "id": "nDOxazi4Vhb4",
    "outputId": "b9d19a69-ad2e-4643-b898-d866c032da51"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import community as community_louvain\n",
    "import re\n",
    "\n",
    "# Load network data (2017)\n",
    "df = pd.read_csv('/content/global-artist_network-2017.csv', sep='\\t', engine='python', quoting=3)\n",
    "df.columns = df.columns.str.strip()\n",
    "edges = df[['artist_1', 'artist_2', 'count']].dropna()\n",
    "edges['count'] = pd.to_numeric(edges['count'], errors='coerce').fillna(1).astype(int)\n",
    "\n",
    "G = nx.Graph()\n",
    "for _, row in edges.iterrows():\n",
    "    G.add_edge(row['artist_1'], row['artist_2'], weight=row['count'])\n",
    "\n",
    "partition = community_louvain.best_partition(G, weight='weight')\n",
    "nx.set_node_attributes(G, partition, 'community')\n",
    "degrees = dict(G.degree(weight='weight'))\n",
    "\n",
    "# Create a DataFrame for each node's community and degree\n",
    "nodes_data = []\n",
    "for node in G.nodes():\n",
    "    deg = degrees.get(node, 0)\n",
    "    comm = partition.get(node, -1)\n",
    "    nodes_data.append({'artist': node, 'degree': deg, 'community': comm})\n",
    "nodes_df = pd.DataFrame(nodes_data)\n",
    "\n",
    "# Calculate the size of each community\n",
    "community_sizes = nodes_df.groupby('community').size()\n",
    "\n",
    "# Minimum community size for labeling\n",
    "min_community_size = 10\n",
    "large_communities = community_sizes[community_sizes >= min_community_size].index\n",
    "\n",
    "# Select representative artists (top N by degree in large communities only)\n",
    "N = 3\n",
    "rep_artist_df = nodes_df[nodes_df['community'].isin(large_communities)] \\\n",
    "    .groupby('community').apply(lambda x: x.nlargest(N, 'degree')).reset_index(drop=True)\n",
    "rep_artist_set = set(rep_artist_df['artist'])\n",
    "\n",
    "# Function to escape special characters in labels\n",
    "def escape_label(label):\n",
    "    return re.sub(r'([$\\\\_^\\{\\}#&%~])', r'\\\\\\1', str(label))\n",
    "\n",
    "# Visualization\n",
    "cmap = plt.get_cmap('tab20')\n",
    "communities = [partition[n] for n in G.nodes()]\n",
    "colors = [cmap(c % 20) for c in communities]\n",
    "node_sizes = [degrees[n]*5 for n in G.nodes()]\n",
    "pos = nx.spring_layout(G, k=0.15, seed=42)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "nx.draw_networkx_nodes(G, pos, node_color=colors, node_size=node_sizes, alpha=0.7)\n",
    "nx.draw_networkx_edges(G, pos, width=[G[u][v]['weight']*0.2 for u, v in G.edges()], alpha=0.2)\n",
    "# Show labels only for representative artists (in large communities)\n",
    "label_dict = {n: escape_label(n) for n in G.nodes() if n in rep_artist_set}\n",
    "nx.draw_networkx_labels(G, pos, labels=label_dict, font_size=10, font_weight='bold')\n",
    "plt.title('2017 Artist Collaboration Network (Labels for Representative Artists in Large Communities)')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 885
    },
    "id": "uYYfIY6wVooQ",
    "outputId": "4510ab51-fdd2-46c9-b25f-ae5f81d0ed01"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import community as community_louvain\n",
    "import re\n",
    "\n",
    "# Load network data (2018)\n",
    "df = pd.read_csv('/content/global-artist_network-2018.csv', sep='\\t', engine='python', quoting=3)\n",
    "df.columns = df.columns.str.strip()\n",
    "edges = df[['artist_1', 'artist_2', 'count']].dropna()\n",
    "edges['count'] = pd.to_numeric(edges['count'], errors='coerce').fillna(1).astype(int)\n",
    "\n",
    "G = nx.Graph()\n",
    "for _, row in edges.iterrows():\n",
    "    G.add_edge(row['artist_1'], row['artist_2'], weight=row['count'])\n",
    "\n",
    "partition = community_louvain.best_partition(G, weight='weight')\n",
    "nx.set_node_attributes(G, partition, 'community')\n",
    "degrees = dict(G.degree(weight='weight'))\n",
    "\n",
    "# Create a DataFrame for each node's community and degree\n",
    "nodes_data = []\n",
    "for node in G.nodes():\n",
    "    deg = degrees.get(node, 0)\n",
    "    comm = partition.get(node, -1)\n",
    "    nodes_data.append({'artist': node, 'degree': deg, 'community': comm})\n",
    "nodes_df = pd.DataFrame(nodes_data)\n",
    "\n",
    "# Calculate the size of each community\n",
    "community_sizes = nodes_df.groupby('community').size()\n",
    "\n",
    "# Minimum community size for labeling\n",
    "min_community_size = 10\n",
    "large_communities = community_sizes[community_sizes >= min_community_size].index\n",
    "\n",
    "# Select representative artists (top N by degree in large communities only)\n",
    "N = 3\n",
    "rep_artist_df = nodes_df[nodes_df['community'].isin(large_communities)] \\\n",
    "    .groupby('community').apply(lambda x: x.nlargest(N, 'degree')).reset_index(drop=True)\n",
    "rep_artist_set = set(rep_artist_df['artist'])\n",
    "\n",
    "# Function to escape special characters in labels\n",
    "def escape_label(label):\n",
    "    return re.sub(r'([$\\\\_^\\{\\}#&%~])', r'\\\\\\1', str(label))\n",
    "\n",
    "# Visualization\n",
    "cmap = plt.get_cmap('tab20')\n",
    "communities = [partition[n] for n in G.nodes()]\n",
    "colors = [cmap(c % 20) for c in communities]\n",
    "node_sizes = [degrees[n]*5 for n in G.nodes()]\n",
    "pos = nx.spring_layout(G, k=0.15, seed=42)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "nx.draw_networkx_nodes(G, pos, node_color=colors, node_size=node_sizes, alpha=0.7)\n",
    "nx.draw_networkx_edges(G, pos, width=[G[u][v]['weight']*0.2 for u, v in G.edges()], alpha=0.2)\n",
    "# Show labels only for representative artists (in large communities)\n",
    "label_dict = {n: escape_label(n) for n in G.nodes() if n in rep_artist_set}\n",
    "nx.draw_networkx_labels(G, pos, labels=label_dict, font_size=10, font_weight='bold')\n",
    "plt.title('2018 Artist Collaboration Network (Labels for Representative Artists in Large Communities)')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 885
    },
    "id": "h9C-KSvaV4UI",
    "outputId": "65103766-1485-4e86-b6d8-63a70b25e95b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import community as community_louvain\n",
    "import re\n",
    "\n",
    "# Load network data (2019)\n",
    "df = pd.read_csv('/content/global-artist_network-2019.csv', sep='\\t', engine='python', quoting=3)\n",
    "df.columns = df.columns.str.strip()\n",
    "edges = df[['artist_1', 'artist_2', 'count']].dropna()\n",
    "edges['count'] = pd.to_numeric(edges['count'], errors='coerce').fillna(1).astype(int)\n",
    "\n",
    "G = nx.Graph()\n",
    "for _, row in edges.iterrows():\n",
    "    G.add_edge(row['artist_1'], row['artist_2'], weight=row['count'])\n",
    "\n",
    "partition = community_louvain.best_partition(G, weight='weight')\n",
    "nx.set_node_attributes(G, partition, 'community')\n",
    "degrees = dict(G.degree(weight='weight'))\n",
    "\n",
    "# Create a DataFrame for each node's community and degree\n",
    "nodes_data = []\n",
    "for node in G.nodes():\n",
    "    deg = degrees.get(node, 0)\n",
    "    comm = partition.get(node, -1)\n",
    "    nodes_data.append({'artist': node, 'degree': deg, 'community': comm})\n",
    "nodes_df = pd.DataFrame(nodes_data)\n",
    "\n",
    "# Calculate the size of each community\n",
    "community_sizes = nodes_df.groupby('community').size()\n",
    "\n",
    "# Minimum community size for labeling\n",
    "min_community_size = 10\n",
    "large_communities = community_sizes[community_sizes >= min_community_size].index\n",
    "\n",
    "# Select representative artists (top N by degree in large communities only)\n",
    "N = 3\n",
    "rep_artist_df = nodes_df[nodes_df['community'].isin(large_communities)] \\\n",
    "    .groupby('community').apply(lambda x: x.nlargest(N, 'degree')).reset_index(drop=True)\n",
    "rep_artist_set = set(rep_artist_df['artist'])\n",
    "\n",
    "# Function to escape special characters in labels\n",
    "def escape_label(label):\n",
    "    return re.sub(r'([$\\\\_^\\{\\}#&%~])', r'\\\\\\1', str(label))\n",
    "\n",
    "# Visualization\n",
    "cmap = plt.get_cmap('tab20')\n",
    "communities = [partition[n] for n in G.nodes()]\n",
    "colors = [cmap(c % 20) for c in communities]\n",
    "node_sizes = [degrees[n]*5 for n in G.nodes()]\n",
    "pos = nx.spring_layout(G, k=0.15, seed=42)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "nx.draw_networkx_nodes(G, pos, node_color=colors, node_size=node_sizes, alpha=0.7)\n",
    "nx.draw_networkx_edges(G, pos, width=[G[u][v]['weight']*0.2 for u, v in G.edges()], alpha=0.2)\n",
    "# Show labels only for representative artists (in large communities)\n",
    "label_dict = {n: escape_label(n) for n in G.nodes() if n in rep_artist_set}\n",
    "nx.draw_networkx_labels(G, pos, labels=label_dict, font_size=10, font_weight='bold')\n",
    "plt.title('2019 Artist Collaboration Network (Labels for Representative Artists in Large Communities)')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZI_0HSRWLG2"
   },
   "source": [
    "## Visualization of Core Artist Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "id": "8v4zTZ2oWA7_",
    "outputId": "377531df-604d-4bfc-c921-e9fb51cec137"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import community as community_louvain\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# --- Load network data and detect communities ---\n",
    "df = pd.read_csv('global-artist_network-2017.csv', sep='\\t', engine='python', quoting=3)\n",
    "df.columns = df.columns.str.strip()\n",
    "edges = df[['artist_1', 'artist_2', 'count']].dropna()\n",
    "edges['count'] = pd.to_numeric(edges['count'], errors='coerce').fillna(1).astype(int)\n",
    "\n",
    "G = nx.Graph()\n",
    "for _, row in edges.iterrows():\n",
    "    G.add_edge(row['artist_1'], row['artist_2'], weight=row['count'])\n",
    "\n",
    "partition = community_louvain.best_partition(G, weight='weight')\n",
    "nx.set_node_attributes(G, partition, 'community')\n",
    "degrees = dict(G.degree(weight='weight'))\n",
    "\n",
    "# --- Select representative artist (top 1 by degree per community) ---\n",
    "nodes_data = []\n",
    "for node in G.nodes():\n",
    "    deg = degrees.get(node, 0)\n",
    "    comm = partition.get(node, -1)\n",
    "    nodes_data.append({'artist': node, 'degree': deg, 'community': comm})\n",
    "nodes_df = pd.DataFrame(nodes_data)\n",
    "\n",
    "# Representative artist (most collaborations) per community\n",
    "rep_artist_df = nodes_df.groupby('community').apply(lambda x: x.nlargest(1, 'degree')).reset_index(drop=True)\n",
    "rep_artist_names = rep_artist_df.set_index('community')['artist'].to_dict()\n",
    "\n",
    "# --- Create community-level graph ---\n",
    "community_graph = nx.Graph()\n",
    "for comm in nodes_df['community'].unique():\n",
    "    community_graph.add_node(comm)\n",
    "\n",
    "for u, v, data in G.edges(data=True):\n",
    "    comm_u = partition[u]\n",
    "    comm_v = partition[v]\n",
    "    if comm_u != comm_v:\n",
    "        key = tuple(sorted([comm_u, comm_v]))\n",
    "        if community_graph.has_edge(*key):\n",
    "            community_graph[key[0]][key[1]]['weight'] += data['weight']\n",
    "        else:\n",
    "            community_graph.add_edge(key[0], key[1], weight=data['weight'])\n",
    "\n",
    "# --- Extract only core communities (with the largest total edge weights) ---\n",
    "# Example: Keep only the top 15 communities by total degree (number of collaborations)\n",
    "community_degrees = {comm: len(nodes_df[nodes_df['community']==comm]) for comm in community_graph.nodes()}\n",
    "top_communities = sorted(community_degrees, key=community_degrees.get, reverse=True)[:15]\n",
    "subgraph = community_graph.subgraph(top_communities).copy()\n",
    "\n",
    "# --- Visualization (minimize node overlap, zoom in) ---\n",
    "def escape_label(label):\n",
    "    return re.sub(r'([$\\\\_^\\{\\}#&%~])', r'\\\\\\1', str(label))\n",
    "\n",
    "sub_labels = {comm: escape_label(rep_artist_names.get(comm, str(comm))) for comm in subgraph.nodes()}\n",
    "node_sizes = [community_degrees[comm]*200 for comm in subgraph.nodes()]\n",
    "edge_widths = [subgraph[u][v]['weight']*0.2 for u,v in subgraph.edges()]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Increasing k spreads nodes further apart (minimizing overlap)\n",
    "pos = nx.spring_layout(subgraph, seed=42, k=5)\n",
    "nx.draw_networkx_nodes(subgraph, pos, node_color='skyblue', node_size=node_sizes)\n",
    "nx.draw_networkx_edges(subgraph, pos, width=edge_widths, alpha=0.6)\n",
    "# Adjust label position slightly above the node\n",
    "for comm, (x, y) in pos.items():\n",
    "    plt.text(x, y+0.07, sub_labels[comm], fontsize=13, fontweight='bold', ha='center', va='bottom')\n",
    "plt.title('2017 Core Community-Level Collaboration Network (Representative Artist Labels)')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "id": "wpbPSvo9WSJT",
    "outputId": "1aa92ca7-2051-4549-e9ac-9d60e9e46928"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import community as community_louvain\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# --- Load network data and detect communities ---\n",
    "df = pd.read_csv('global-artist_network-2018.csv', sep='\\t', engine='python', quoting=3)\n",
    "df.columns = df.columns.str.strip()\n",
    "edges = df[['artist_1', 'artist_2', 'count']].dropna()\n",
    "edges['count'] = pd.to_numeric(edges['count'], errors='coerce').fillna(1).astype(int)\n",
    "\n",
    "G = nx.Graph()\n",
    "for _, row in edges.iterrows():\n",
    "    G.add_edge(row['artist_1'], row['artist_2'], weight=row['count'])\n",
    "\n",
    "partition = community_louvain.best_partition(G, weight='weight')\n",
    "nx.set_node_attributes(G, partition, 'community')\n",
    "degrees = dict(G.degree(weight='weight'))\n",
    "\n",
    "# --- Select representative artist (top 1 by degree per community) ---\n",
    "nodes_data = []\n",
    "for node in G.nodes():\n",
    "    deg = degrees.get(node, 0)\n",
    "    comm = partition.get(node, -1)\n",
    "    nodes_data.append({'artist': node, 'degree': deg, 'community': comm})\n",
    "nodes_df = pd.DataFrame(nodes_data)\n",
    "\n",
    "# Representative artist (most collaborations) per community\n",
    "rep_artist_df = nodes_df.groupby('community').apply(lambda x: x.nlargest(1, 'degree')).reset_index(drop=True)\n",
    "rep_artist_names = rep_artist_df.set_index('community')['artist'].to_dict()\n",
    "\n",
    "# --- Create community-level graph ---\n",
    "community_graph = nx.Graph()\n",
    "for comm in nodes_df['community'].unique():\n",
    "    community_graph.add_node(comm)\n",
    "\n",
    "for u, v, data in G.edges(data=True):\n",
    "    comm_u = partition[u]\n",
    "    comm_v = partition[v]\n",
    "    if comm_u != comm_v:\n",
    "        key = tuple(sorted([comm_u, comm_v]))\n",
    "        if community_graph.has_edge(*key):\n",
    "            community_graph[key[0]][key[1]]['weight'] += data['weight']\n",
    "        else:\n",
    "            community_graph.add_edge(key[0], key[1], weight=data['weight'])\n",
    "\n",
    "# --- Extract only core communities (with the largest total edge weights) ---\n",
    "# Example: Keep only the top 15 communities by total degree (number of collaborations)\n",
    "community_degrees = {comm: len(nodes_df[nodes_df['community']==comm]) for comm in community_graph.nodes()}\n",
    "top_communities = sorted(community_degrees, key=community_degrees.get, reverse=True)[:15]\n",
    "subgraph = community_graph.subgraph(top_communities).copy()\n",
    "\n",
    "# --- Visualization (minimize node overlap, zoom in) ---\n",
    "def escape_label(label):\n",
    "    return re.sub(r'([$\\\\_^\\{\\}#&%~])', r'\\\\\\1', str(label))\n",
    "\n",
    "sub_labels = {comm: escape_label(rep_artist_names.get(comm, str(comm))) for comm in subgraph.nodes()}\n",
    "node_sizes = [community_degrees[comm]*200 for comm in subgraph.nodes()]\n",
    "edge_widths = [subgraph[u][v]['weight']*0.2 for u,v in subgraph.edges()]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Increasing k spreads nodes further apart (minimizing overlap)\n",
    "pos = nx.spring_layout(subgraph, seed=42, k=5)\n",
    "nx.draw_networkx_nodes(subgraph, pos, node_color='skyblue', node_size=node_sizes)\n",
    "nx.draw_networkx_edges(subgraph, pos, width=edge_widths, alpha=0.6)\n",
    "# Adjust label position slightly above the node\n",
    "for comm, (x, y) in pos.items():\n",
    "    plt.text(x, y+0.07, sub_labels[comm], fontsize=13, fontweight='bold', ha='center', va='bottom')\n",
    "plt.title('2018 Core Community-Level Collaboration Network (Representative Artist Labels)')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "id": "05GBLkJYWdkz",
    "outputId": "da0a52c5-b723-44f3-833a-e2afb7e508ef"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import community as community_louvain\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# --- Load network data and detect communities ---\n",
    "df = pd.read_csv('global-artist_network-2019.csv', sep='\\t', engine='python', quoting=3)\n",
    "df.columns = df.columns.str.strip()\n",
    "edges = df[['artist_1', 'artist_2', 'count']].dropna()\n",
    "edges['count'] = pd.to_numeric(edges['count'], errors='coerce').fillna(1).astype(int)\n",
    "\n",
    "G = nx.Graph()\n",
    "for _, row in edges.iterrows():\n",
    "    G.add_edge(row['artist_1'], row['artist_2'], weight=row['count'])\n",
    "\n",
    "partition = community_louvain.best_partition(G, weight='weight')\n",
    "nx.set_node_attributes(G, partition, 'community')\n",
    "degrees = dict(G.degree(weight='weight'))\n",
    "\n",
    "# --- Select representative artist (top 1 by degree per community) ---\n",
    "nodes_data = []\n",
    "for node in G.nodes():\n",
    "    deg = degrees.get(node, 0)\n",
    "    comm = partition.get(node, -1)\n",
    "    nodes_data.append({'artist': node, 'degree': deg, 'community': comm})\n",
    "nodes_df = pd.DataFrame(nodes_data)\n",
    "\n",
    "# Representative artist (most collaborations) per community\n",
    "rep_artist_df = nodes_df.groupby('community').apply(lambda x: x.nlargest(1, 'degree')).reset_index(drop=True)\n",
    "rep_artist_names = rep_artist_df.set_index('community')['artist'].to_dict()\n",
    "\n",
    "# --- Create community-level graph ---\n",
    "community_graph = nx.Graph()\n",
    "for comm in nodes_df['community'].unique():\n",
    "    community_graph.add_node(comm)\n",
    "\n",
    "for u, v, data in G.edges(data=True):\n",
    "    comm_u = partition[u]\n",
    "    comm_v = partition[v]\n",
    "    if comm_u != comm_v:\n",
    "        key = tuple(sorted([comm_u, comm_v]))\n",
    "        if community_graph.has_edge(*key):\n",
    "            community_graph[key[0]][key[1]]['weight'] += data['weight']\n",
    "        else:\n",
    "            community_graph.add_edge(key[0], key[1], weight=data['weight'])\n",
    "\n",
    "# --- Extract only core communities (with the largest total edge weights) ---\n",
    "# Example: Keep only the top 15 communities by total degree (number of collaborations)\n",
    "community_degrees = {comm: len(nodes_df[nodes_df['community']==comm]) for comm in community_graph.nodes()}\n",
    "top_communities = sorted(community_degrees, key=community_degrees.get, reverse=True)[:15]\n",
    "subgraph = community_graph.subgraph(top_communities).copy()\n",
    "\n",
    "# --- Visualization (minimize node overlap, zoom in) ---\n",
    "def escape_label(label):\n",
    "    return re.sub(r'([$\\\\_^\\{\\}#&%~])', r'\\\\\\1', str(label))\n",
    "\n",
    "sub_labels = {comm: escape_label(rep_artist_names.get(comm, str(comm))) for comm in subgraph.nodes()}\n",
    "node_sizes = [community_degrees[comm]*200 for comm in subgraph.nodes()]\n",
    "edge_widths = [subgraph[u][v]['weight']*0.2 for u,v in subgraph.edges()]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Increasing k spreads nodes further apart (minimizing overlap)\n",
    "pos = nx.spring_layout(subgraph, seed=42, k=5)\n",
    "nx.draw_networkx_nodes(subgraph, pos, node_color='skyblue', node_size=node_sizes)\n",
    "nx.draw_networkx_edges(subgraph, pos, width=edge_widths, alpha=0.6)\n",
    "# Adjust label position slightly above the node\n",
    "for comm, (x, y) in pos.items():\n",
    "    plt.text(x, y+0.07, sub_labels[comm], fontsize=13, fontweight='bold', ha='center', va='bottom')\n",
    "plt.title('2019 Core Community-Level Collaboration Network (Representative Artist Labels)')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkVHsJilWwF-"
   },
   "source": [
    "### Genre Distribution Aggregation for Top 15 Communities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5OJ_svBhWjKp",
    "outputId": "1f26d19a-6599-4f42-f7e6-e0ea09d1b858"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# 1. Load artist information\n",
    "artists_info = pd.read_csv('/content/spotify_artists_info_complete.csv', sep='\\t', encoding='utf-8')\n",
    "artists_info = artists_info.drop_duplicates(subset=['name'], keep='first')\n",
    "artist_genre_map = artists_info.set_index('name')['genres'].to_dict()\n",
    "\n",
    "# 2. Build network and assign communities\n",
    "df = pd.read_csv('/content/global-artist_network-2017.csv', sep='\\t', engine='python', quoting=3)\n",
    "df.columns = df.columns.str.strip()\n",
    "edges = df[['artist_1', 'artist_2', 'count']].dropna()\n",
    "edges['count'] = pd.to_numeric(edges['count'], errors='coerce').fillna(1).astype(int)\n",
    "G = nx.Graph()\n",
    "for _, row in edges.iterrows():\n",
    "    G.add_edge(row['artist_1'], row['artist_2'], weight=row['count'])\n",
    "partition = community_louvain.best_partition(G, weight='weight')\n",
    "nx.set_node_attributes(G, partition, 'community')\n",
    "degrees = dict(G.degree(weight='weight'))\n",
    "\n",
    "# 3. Calculate total degree (collaboration strength) per community\n",
    "community_degree = {}\n",
    "for comm in set(partition.values()):\n",
    "    nodes = [n for n, c in partition.items() if c == comm]\n",
    "    deg_sum = sum(dict(G.degree(nodes, weight='weight')).values())\n",
    "    community_degree[comm] = deg_sum\n",
    "\n",
    "# 4. Select top 15 communities (by total degree)\n",
    "top_15_communities = sorted(community_degree, key=community_degree.get, reverse=True)[:15]\n",
    "\n",
    "# 5. Select representative artist (top 1 by degree) and community size for each community\n",
    "nodes_data = []\n",
    "for node in G.nodes():\n",
    "    deg = degrees.get(node, 0)\n",
    "    comm = partition.get(node, -1)\n",
    "    nodes_data.append({'artist': node, 'degree': deg, 'community': comm})\n",
    "nodes_df = pd.DataFrame(nodes_data)\n",
    "rep_artist_df = nodes_df[nodes_df['community'].isin(top_15_communities)] \\\n",
    "    .groupby('community').apply(lambda x: x.nlargest(1, 'degree')).reset_index(drop=True)\n",
    "rep_artist_names = rep_artist_df.set_index('community')['artist'].to_dict()\n",
    "community_sizes = nodes_df['community'].value_counts().to_dict()\n",
    "\n",
    "# 6. Aggregate genre distribution for each community (top 15 only)\n",
    "community_genres = {}\n",
    "for node, comm in partition.items():\n",
    "    if comm in top_15_communities:\n",
    "        genres = artist_genre_map.get(node, '')\n",
    "        for genre in str(genres).split(','):\n",
    "            if comm not in community_genres:\n",
    "                community_genres[comm] = []\n",
    "            community_genres[comm].append(genre.strip())\n",
    "\n",
    "cmap = plt.get_cmap('tab20')\n",
    "for comm in top_15_communities:\n",
    "    if comm in community_genres:\n",
    "        genre_counts = Counter(community_genres[comm])\n",
    "        top_genres = genre_counts.most_common(10)\n",
    "        labels, counts = zip(*top_genres)\n",
    "        rep_artist = rep_artist_names.get(comm, f'Community {comm}')\n",
    "        comm_size = community_sizes.get(comm, 0)\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.bar(labels, counts, color=cmap(comm % 20))\n",
    "        plt.title(f\"Community {comm} ({rep_artist}, size={comm_size}) - Top 10 Genres (2017)\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f'Community {comm} has no genre data.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7s1oonGqW0XU",
    "outputId": "695834fa-3c54-491b-dc12-3d63aafd66f6"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# 1. Load artist information\n",
    "artists_info = pd.read_csv('/content/spotify_artists_info_complete.csv', sep='\\t', encoding='utf-8')\n",
    "artists_info = artists_info.drop_duplicates(subset=['name'], keep='first')\n",
    "artist_genre_map = artists_info.set_index('name')['genres'].to_dict()\n",
    "\n",
    "# 2. Build network and assign communities\n",
    "df = pd.read_csv('/content/global-artist_network-2018.csv', sep='\\t', engine='python', quoting=3)\n",
    "df.columns = df.columns.str.strip()\n",
    "edges = df[['artist_1', 'artist_2', 'count']].dropna()\n",
    "edges['count'] = pd.to_numeric(edges['count'], errors='coerce').fillna(1).astype(int)\n",
    "G = nx.Graph()\n",
    "for _, row in edges.iterrows():\n",
    "    G.add_edge(row['artist_1'], row['artist_2'], weight=row['count'])\n",
    "partition = community_louvain.best_partition(G, weight='weight')\n",
    "nx.set_node_attributes(G, partition, 'community')\n",
    "degrees = dict(G.degree(weight='weight'))\n",
    "\n",
    "# 3. Calculate total degree (collaboration strength) per community\n",
    "community_degree = {}\n",
    "for comm in set(partition.values()):\n",
    "    nodes = [n for n, c in partition.items() if c == comm]\n",
    "    deg_sum = sum(dict(G.degree(nodes, weight='weight')).values())\n",
    "    community_degree[comm] = deg_sum\n",
    "\n",
    "# 4. Select top 15 communities (by total degree)\n",
    "top_15_communities = sorted(community_degree, key=community_degree.get, reverse=True)[:15]\n",
    "\n",
    "# 5. Select representative artist (top 1 by degree) and community size for each community\n",
    "nodes_data = []\n",
    "for node in G.nodes():\n",
    "    deg = degrees.get(node, 0)\n",
    "    comm = partition.get(node, -1)\n",
    "    nodes_data.append({'artist': node, 'degree': deg, 'community': comm})\n",
    "nodes_df = pd.DataFrame(nodes_data)\n",
    "rep_artist_df = nodes_df[nodes_df['community'].isin(top_15_communities)] \\\n",
    "    .groupby('community').apply(lambda x: x.nlargest(1, 'degree')).reset_index(drop=True)\n",
    "rep_artist_names = rep_artist_df.set_index('community')['artist'].to_dict()\n",
    "community_sizes = nodes_df['community'].value_counts().to_dict()\n",
    "\n",
    "# 6. Aggregate genre distribution for each community (top 15 only)\n",
    "community_genres = {}\n",
    "for node, comm in partition.items():\n",
    "    if comm in top_15_communities:\n",
    "        genres = artist_genre_map.get(node, '')\n",
    "        for genre in str(genres).split(','):\n",
    "            if comm not in community_genres:\n",
    "                community_genres[comm] = []\n",
    "            community_genres[comm].append(genre.strip())\n",
    "\n",
    "cmap = plt.get_cmap('tab20')\n",
    "for comm in top_15_communities:\n",
    "    if comm in community_genres:\n",
    "        genre_counts = Counter(community_genres[comm])\n",
    "        top_genres = genre_counts.most_common(10)\n",
    "        labels, counts = zip(*top_genres)\n",
    "        rep_artist = rep_artist_names.get(comm, f'Community {comm}')\n",
    "        comm_size = community_sizes.get(comm, 0)\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.bar(labels, counts, color=cmap(comm % 20))\n",
    "        plt.title(f\"Community {comm} ({rep_artist}, size={comm_size}) - Top 10 Genres (2018)\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f'Community {comm} has no genre data.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1Ue4hAw1XIiu",
    "outputId": "95d25729-0fe9-4e11-f7d2-7862990e4978"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# 1. Load artist information\n",
    "artists_info = pd.read_csv('/content/spotify_artists_info_complete.csv', sep='\\t', encoding='utf-8')\n",
    "artists_info = artists_info.drop_duplicates(subset=['name'], keep='first')\n",
    "artist_genre_map = artists_info.set_index('name')['genres'].to_dict()\n",
    "\n",
    "# 2. Build network and assign communities\n",
    "df = pd.read_csv('/content/global-artist_network-2019.csv', sep='\\t', engine='python', quoting=3)\n",
    "df.columns = df.columns.str.strip()\n",
    "edges = df[['artist_1', 'artist_2', 'count']].dropna()\n",
    "edges['count'] = pd.to_numeric(edges['count'], errors='coerce').fillna(1).astype(int)\n",
    "G = nx.Graph()\n",
    "for _, row in edges.iterrows():\n",
    "    G.add_edge(row['artist_1'], row['artist_2'], weight=row['count'])\n",
    "partition = community_louvain.best_partition(G, weight='weight')\n",
    "nx.set_node_attributes(G, partition, 'community')\n",
    "degrees = dict(G.degree(weight='weight'))\n",
    "\n",
    "# 3. Calculate total degree (collaboration strength) per community\n",
    "community_degree = {}\n",
    "for comm in set(partition.values()):\n",
    "    nodes = [n for n, c in partition.items() if c == comm]\n",
    "    deg_sum = sum(dict(G.degree(nodes, weight='weight')).values())\n",
    "    community_degree[comm] = deg_sum\n",
    "\n",
    "# 4. Select top 15 communities (by total degree)\n",
    "top_15_communities = sorted(community_degree, key=community_degree.get, reverse=True)[:15]\n",
    "\n",
    "# 5. Select representative artist (top 1 by degree) and community size for each community\n",
    "nodes_data = []\n",
    "for node in G.nodes():\n",
    "    deg = degrees.get(node, 0)\n",
    "    comm = partition.get(node, -1)\n",
    "    nodes_data.append({'artist': node, 'degree': deg, 'community': comm})\n",
    "nodes_df = pd.DataFrame(nodes_data)\n",
    "rep_artist_df = nodes_df[nodes_df['community'].isin(top_15_communities)] \\\n",
    "    .groupby('community').apply(lambda x: x.nlargest(1, 'degree')).reset_index(drop=True)\n",
    "rep_artist_names = rep_artist_df.set_index('community')['artist'].to_dict()\n",
    "community_sizes = nodes_df['community'].value_counts().to_dict()\n",
    "\n",
    "# 6. Aggregate genre distribution for each community (top 15 only)\n",
    "community_genres = {}\n",
    "for node, comm in partition.items():\n",
    "    if comm in top_15_communities:\n",
    "        genres = artist_genre_map.get(node, '')\n",
    "        for genre in str(genres).split(','):\n",
    "            if comm not in community_genres:\n",
    "                community_genres[comm] = []\n",
    "            community_genres[comm].append(genre.strip())\n",
    "\n",
    "cmap = plt.get_cmap('tab20')\n",
    "for comm in top_15_communities:\n",
    "    if comm in community_genres:\n",
    "        genre_counts = Counter(community_genres[comm])\n",
    "        top_genres = genre_counts.most_common(10)\n",
    "        labels, counts = zip(*top_genres)\n",
    "        rep_artist = rep_artist_names.get(comm, f'Community {comm}')\n",
    "        comm_size = community_sizes.get(comm, 0)\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.bar(labels, counts, color=cmap(comm % 20))\n",
    "        plt.title(f\"Community {comm} ({rep_artist}, size={comm_size}) - Top 10 Genres (2019)\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f'Community {comm} has no genre data.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlQA2vAeX43g"
   },
   "source": [
    "# Genre Network Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AuEDcFB4XOIJ",
    "outputId": "253f9761-63dc-41e6-e7e9-586a8032a05c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "\n",
    "# 1. Load files\n",
    "artist_network = pd.read_csv('/content/global-artist_network-2017.csv', sep='\\t', engine='python', quoting=3)\n",
    "artists_info = pd.read_csv('/content/spotify_artists_info_complete.csv', sep='\\t', encoding='utf-8')\n",
    "artists_info = artists_info.drop_duplicates(subset=['name'], keep='first')\n",
    "artist_genre_map = artists_info.set_index('name')['genres'].to_dict()\n",
    "\n",
    "# 2. Build genre network\n",
    "genre_G = nx.Graph()\n",
    "\n",
    "for idx, row in artist_network.iterrows():\n",
    "    a1, a2, count = row['artist_1'], row['artist_2'], row['count']\n",
    "    genres1 = artist_genre_map.get(a1, '')\n",
    "    genres2 = artist_genre_map.get(a2, '')\n",
    "    # If genres are stored as strings, split by comma (or whitespace if needed)\n",
    "    if isinstance(genres1, str):\n",
    "        genres1 = [g.strip() for g in genres1.replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(',') if g.strip()]\n",
    "    if isinstance(genres2, str):\n",
    "        genres2 = [g.strip() for g in genres2.replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(',') if g.strip()]\n",
    "    # Create all genre pairs\n",
    "    for g1 in genres1:\n",
    "        for g2 in genres2:\n",
    "            if not g1 or not g2:\n",
    "                continue\n",
    "            # Undirected network: sort alphabetically to avoid duplicates\n",
    "            edge = tuple(sorted([g1, g2]))\n",
    "            if genre_G.has_edge(edge[0], edge[1]):\n",
    "                genre_G[edge[0]][edge[1]]['weight'] += int(count)\n",
    "            else:\n",
    "                genre_G.add_edge(edge[0], edge[1], weight=int(count))\n",
    "\n",
    "print(f\"Number of genre nodes: {genre_G.number_of_nodes()}\")\n",
    "print(f\"Number of genre edges: {genre_G.number_of_edges()}\")\n",
    "\n",
    "# Print top genre collaboration pairs\n",
    "top_edges = sorted(genre_G.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)[:15]\n",
    "print(\"\\nTop 15 genre-genre collaborations:\")\n",
    "for g1, g2, data in top_edges:\n",
    "    print(f\"{g1} - {g2}: {data['weight']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uCBb_UprX9FD",
    "outputId": "5a3abdde-24f1-4955-e53e-977b46d54eb1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Data loading\n",
    "artist_network = pd.read_csv('/content/global-artist_network-2017.csv', sep='\\t', engine='python', quoting=3)\n",
    "artists_info = pd.read_csv('/content/spotify_artists_info_complete.csv', sep='\\t', encoding='utf-8')\n",
    "artists_info = artists_info.drop_duplicates(subset=['name'], keep='first')\n",
    "artist_genre_map = artists_info.set_index('name')['genres'].to_dict()\n",
    "\n",
    "# 2. Build genre network\n",
    "genre_G = nx.Graph()\n",
    "for idx, row in artist_network.iterrows():\n",
    "    a1, a2, count = row['artist_1'], row['artist_2'], row['count']\n",
    "    genres1 = artist_genre_map.get(a1, '')\n",
    "    genres2 = artist_genre_map.get(a2, '')\n",
    "    # Clean and split genre strings\n",
    "    if isinstance(genres1, str):\n",
    "        genres1 = [g.strip().strip(\"'[]\") for g in genres1.split(',') if g.strip()]\n",
    "    if isinstance(genres2, str):\n",
    "        genres2 = [g.strip().strip(\"'[]\") for g in genres2.split(',') if g.strip()]\n",
    "    # Add edges for each genre pair\n",
    "    for g1 in genres1:\n",
    "        for g2 in genres2:\n",
    "            if not g1 or not g2:\n",
    "                continue\n",
    "            edge = tuple(sorted([g1, g2]))\n",
    "            if genre_G.has_edge(*edge):\n",
    "                genre_G[edge[0]][edge[1]]['weight'] += int(count)\n",
    "            else:\n",
    "                genre_G.add_edge(edge[0], edge[1], weight=int(count))\n",
    "\n",
    "# 3. Visualize the network (top collaboration genres only)\n",
    "# Since there are many nodes, show only top 100 edges by weight\n",
    "edges_to_draw = sorted(genre_G.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)[:100]\n",
    "subG = nx.Graph()\n",
    "for g1, g2, data in edges_to_draw:\n",
    "    subG.add_edge(g1, g2, weight=data['weight'])\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "pos = nx.spring_layout(subG, k=0.8, seed=42)\n",
    "edge_widths = [subG[u][v]['weight']*0.05 for u, v in subG.edges()]\n",
    "nx.draw_networkx_nodes(subG, pos, node_color='skyblue', node_size=600, alpha=0.8)\n",
    "nx.draw_networkx_edges(subG, pos, width=edge_widths, alpha=0.5)\n",
    "nx.draw_networkx_labels(subG, pos, font_size=10, font_weight='bold')\n",
    "plt.title('Genre Collaboration Network (Top 100 Edges by Weight, 2017)')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "l-Llr1t1YOaS",
    "outputId": "e54a1154-c527-400f-bd90-caba1e0b030f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Data loading\n",
    "artist_network = pd.read_csv('/content/global-artist_network-2018.csv', sep='\\t', engine='python', quoting=3)\n",
    "artists_info = pd.read_csv('/content/spotify_artists_info_complete.csv', sep='\\t', encoding='utf-8')\n",
    "artists_info = artists_info.drop_duplicates(subset=['name'], keep='first')\n",
    "artist_genre_map = artists_info.set_index('name')['genres'].to_dict()\n",
    "\n",
    "# 2. Build genre network\n",
    "genre_G = nx.Graph()\n",
    "for idx, row in artist_network.iterrows():\n",
    "    a1, a2, count = row['artist_1'], row['artist_2'], row['count']\n",
    "    genres1 = artist_genre_map.get(a1, '')\n",
    "    genres2 = artist_genre_map.get(a2, '')\n",
    "    # Clean and split genre strings\n",
    "    if isinstance(genres1, str):\n",
    "        genres1 = [g.strip().strip(\"'[]\") for g in genres1.split(',') if g.strip()]\n",
    "    if isinstance(genres2, str):\n",
    "        genres2 = [g.strip().strip(\"'[]\") for g in genres2.split(',') if g.strip()]\n",
    "    # Add edges for each genre pair\n",
    "    for g1 in genres1:\n",
    "        for g2 in genres2:\n",
    "            if not g1 or not g2:\n",
    "                continue\n",
    "            edge = tuple(sorted([g1, g2]))\n",
    "            if genre_G.has_edge(*edge):\n",
    "                genre_G[edge[0]][edge[1]]['weight'] += int(count)\n",
    "            else:\n",
    "                genre_G.add_edge(edge[0], edge[1], weight=int(count))\n",
    "\n",
    "# 3. Visualize the network (top collaboration genres only)\n",
    "# Since there are many nodes, show only top 100 edges by weight\n",
    "edges_to_draw = sorted(genre_G.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)[:100]\n",
    "subG = nx.Graph()\n",
    "for g1, g2, data in edges_to_draw:\n",
    "    subG.add_edge(g1, g2, weight=data['weight'])\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "pos = nx.spring_layout(subG, k=0.8, seed=42)\n",
    "edge_widths = [subG[u][v]['weight']*0.05 for u, v in subG.edges()]\n",
    "nx.draw_networkx_nodes(subG, pos, node_color='skyblue', node_size=600, alpha=0.8)\n",
    "nx.draw_networkx_edges(subG, pos, width=edge_widths, alpha=0.5)\n",
    "nx.draw_networkx_labels(subG, pos, font_size=10, font_weight='bold')\n",
    "plt.title('Genre Collaboration Network (Top 100 Edges by Weight, 2018)')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wmx6XxYDYS95",
    "outputId": "419a85b4-18db-4a87-819c-5b4740986f44"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Data loading\n",
    "artist_network = pd.read_csv('/content/global-artist_network-2019.csv', sep='\\t', engine='python', quoting=3)\n",
    "artists_info = pd.read_csv('/content/spotify_artists_info_complete.csv', sep='\\t', encoding='utf-8')\n",
    "artists_info = artists_info.drop_duplicates(subset=['name'], keep='first')\n",
    "artist_genre_map = artists_info.set_index('name')['genres'].to_dict()\n",
    "\n",
    "# 2. Build genre network\n",
    "genre_G = nx.Graph()\n",
    "for idx, row in artist_network.iterrows():\n",
    "    a1, a2, count = row['artist_1'], row['artist_2'], row['count']\n",
    "    genres1 = artist_genre_map.get(a1, '')\n",
    "    genres2 = artist_genre_map.get(a2, '')\n",
    "    # Clean and split genre strings\n",
    "    if isinstance(genres1, str):\n",
    "        genres1 = [g.strip().strip(\"'[]\") for g in genres1.split(',') if g.strip()]\n",
    "    if isinstance(genres2, str):\n",
    "        genres2 = [g.strip().strip(\"'[]\") for g in genres2.split(',') if g.strip()]\n",
    "    # Add edges for each genre pair\n",
    "    for g1 in genres1:\n",
    "        for g2 in genres2:\n",
    "            if not g1 or not g2:\n",
    "                continue\n",
    "            edge = tuple(sorted([g1, g2]))\n",
    "            if genre_G.has_edge(*edge):\n",
    "                genre_G[edge[0]][edge[1]]['weight'] += int(count)\n",
    "            else:\n",
    "                genre_G.add_edge(edge[0], edge[1], weight=int(count))\n",
    "\n",
    "# 3. Visualize the network (top collaboration genres only)\n",
    "# Since there are many nodes, show only top 100 edges by weight\n",
    "edges_to_draw = sorted(genre_G.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)[:100]\n",
    "subG = nx.Graph()\n",
    "for g1, g2, data in edges_to_draw:\n",
    "    subG.add_edge(g1, g2, weight=data['weight'])\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "pos = nx.spring_layout(subG, k=0.8, seed=42)\n",
    "edge_widths = [subG[u][v]['weight']*0.05 for u, v in subG.edges()]\n",
    "nx.draw_networkx_nodes(subG, pos, node_color='skyblue', node_size=600, alpha=0.8)\n",
    "nx.draw_networkx_edges(subG, pos, width=edge_widths, alpha=0.5)\n",
    "nx.draw_networkx_labels(subG, pos, font_size=10, font_weight='bold')\n",
    "plt.title('Genre Collaboration Network (Top 100 Edges by Weight, 2019)')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "X3jQqATmYV2E",
    "outputId": "8d3e494c-bdec-47fa-d47c-07b0c7ec34bf"
   },
   "outputs": [],
   "source": [
    "# Genre network analysis and visualization for 2017-2019\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# File paths\n",
    "files = {\n",
    "    2017: '/content/global-artist_network-2017.csv',\n",
    "    2018: '/content/global-artist_network-2018.csv',\n",
    "    2019: '/content/global-artist_network-2019.csv'\n",
    "}\n",
    "artists_info = pd.read_csv('/content/spotify_artists_info_complete.csv', sep='\\t', encoding='utf-8')\n",
    "artists_info = artists_info.drop_duplicates(subset=['name'], keep='first')\n",
    "artist_genre_map = artists_info.set_index('name')['genres'].to_dict()\n",
    "\n",
    "def build_genre_network(network_file):\n",
    "    # Load network data\n",
    "    df = pd.read_csv(network_file, sep=None, engine='python')\n",
    "    if 'artist_1' not in df.columns:\n",
    "        df.columns = [c.strip() for c in df.columns]\n",
    "    edges = df[['artist_1', 'artist_2', 'count']].dropna()\n",
    "    edges['count'] = pd.to_numeric(edges['count'], errors='coerce').fillna(1).astype(int)\n",
    "    # Build genre network\n",
    "    G = nx.Graph()\n",
    "    for _, row in edges.iterrows():\n",
    "        a1, a2, count = row['artist_1'], row['artist_2'], row['count']\n",
    "        genres1 = artist_genre_map.get(a1, '')\n",
    "        genres2 = artist_genre_map.get(a2, '')\n",
    "        # Clean genre strings\n",
    "        if isinstance(genres1, str):\n",
    "            genres1 = [g.strip().strip(\"'[]\") for g in genres1.split(',') if g.strip()]\n",
    "        if isinstance(genres2, str):\n",
    "            genres2 = [g.strip().strip(\"'[]\") for g in genres2.split(',') if g.strip()]\n",
    "        for g1 in genres1:\n",
    "            for g2 in genres2:\n",
    "                if not g1 or not g2:\n",
    "                    continue\n",
    "                edge = tuple(sorted([g1, g2]))\n",
    "                if G.has_edge(*edge):\n",
    "                    G[edge[0]][edge[1]]['weight'] += int(count)\n",
    "                else:\n",
    "                    G.add_edge(edge[0], edge[1], weight=int(count))\n",
    "    return G\n",
    "\n",
    "def analyze_and_visualize_genre_network(G, year):\n",
    "    # Community detection\n",
    "    partition = community_louvain.best_partition(G, weight='weight')\n",
    "    nx.set_node_attributes(G, partition, 'community')\n",
    "    communities = set(partition.values())\n",
    "    print(f\"\\n=== {year} Genre Network Analysis ===\")\n",
    "    # Community-wise top genres, entropy, crossover\n",
    "    comm_to_genres = {}\n",
    "    for node, comm in partition.items():\n",
    "        comm_to_genres.setdefault(comm, []).append(node)\n",
    "    for comm, genres in comm_to_genres.items():\n",
    "        genre_counts = Counter(genres)\n",
    "        total = sum(genre_counts.values())\n",
    "        probs = np.array(list(genre_counts.values())) / total if total > 0 else np.array([1])\n",
    "        entropy = -np.sum(probs * np.log2(probs))\n",
    "        top_genres = genre_counts.most_common(5)\n",
    "        print(f\"Community {comm}: #genres={len(genres)}, entropy={entropy:.2f}, top genres={top_genres}\")\n",
    "    # Network visualization (top 100 edges)\n",
    "    top_edges = sorted(G.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)[:100]\n",
    "    subG = nx.Graph()\n",
    "    for g1, g2, data in top_edges:\n",
    "        subG.add_edge(g1, g2, weight=data['weight'])\n",
    "    sub_partition = {n: partition[n] for n in subG.nodes()}\n",
    "    cmap = plt.get_cmap('tab20')\n",
    "    node_colors = [cmap(sub_partition[n] % 20) for n in subG.nodes()]\n",
    "    node_sizes = [subG.degree(n, weight='weight')*10 for n in subG.nodes()]\n",
    "    pos = nx.spring_layout(subG, k=1.2, seed=42)\n",
    "    plt.figure(figsize=(14, 11))\n",
    "    nx.draw_networkx_nodes(subG, pos, node_color=node_colors, node_size=node_sizes, alpha=0.85)\n",
    "    nx.draw_networkx_edges(subG, pos, width=[subG[u][v]['weight']*0.1 for u, v in subG.edges()], alpha=0.5)\n",
    "    nx.draw_networkx_labels(subG, pos, font_size=9, font_weight='bold')\n",
    "    plt.title(f\"{year} Genre Collaboration Network (Top 100 Edges)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    # Centrality and participation coefficient\n",
    "    deg = nx.degree_centrality(G)\n",
    "    btw = nx.betweenness_centrality(G, weight='weight')\n",
    "    def participation_coefficient(G, partition):\n",
    "        pc = {}\n",
    "        for node in G.nodes():\n",
    "            comm = partition[node]\n",
    "            deg_node = G.degree(node)\n",
    "            if deg_node == 0:\n",
    "                pc[node] = 0\n",
    "                continue\n",
    "            comm_deg = Counter()\n",
    "            for nbr in G.neighbors(node):\n",
    "                nbr_comm = partition[nbr]\n",
    "                comm_deg[nbr_comm] += 1\n",
    "            sum_sq = sum((count/deg_node)**2 for count in comm_deg.values())\n",
    "            pc[node] = 1 - sum_sq\n",
    "        return pc\n",
    "    pc = participation_coefficient(G, partition)\n",
    "    # Hub/bridge genres\n",
    "    bridge_df = pd.DataFrame({\n",
    "        'genre': list(G.nodes()),\n",
    "        'community': [partition[n] for n in G.nodes()],\n",
    "        'degree_centrality': [deg[n] for n in G.nodes()],\n",
    "        'participation_coeff': [pc[n] for n in G.nodes()],\n",
    "        'betweenness': [btw[n] for n in G.nodes()]\n",
    "    })\n",
    "    print(\"\\nHub/Bridge genres (top 10 by participation_coeff, betweenness):\")\n",
    "    bridges = bridge_df.sort_values(['participation_coeff', 'betweenness'], ascending=False).head(10)\n",
    "    print(bridges[['genre', 'community', 'degree_centrality', 'participation_coeff', 'betweenness']])\n",
    "\n",
    "# Run for each year\n",
    "for year, path in files.items():\n",
    "    Gg = build_genre_network(path)\n",
    "    analyze_and_visualize_genre_network(Gg, year)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgzgovgkY2ja"
   },
   "source": [
    "# Artists who played a central (hub/bridge) role in both artist and genre collaboration networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L71jbJGmYoBj",
    "outputId": "3e9a5756-7ad3-4a83-b389-6107612c46e1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "from collections import Counter\n",
    "\n",
    "# 1. Load artist information\n",
    "artists_info = pd.read_csv('/content/spotify_artists_info_complete.csv', sep='\\t', encoding='utf-8')\n",
    "artists_info = artists_info.drop_duplicates(subset=['name'], keep='first')\n",
    "artist_genre_map = artists_info.set_index('name')['genres'].to_dict()\n",
    "\n",
    "# 2. Build artist collaboration network\n",
    "edges = pd.read_csv('/content/global-artist_network-2017.csv', sep='\\t', engine='python', quoting=3)\n",
    "edges = edges[['artist_1', 'artist_2', 'count']].dropna()\n",
    "edges['count'] = pd.to_numeric(edges['count'], errors='coerce').fillna(1).astype(int)\n",
    "G = nx.Graph()\n",
    "for _, row in edges.iterrows():\n",
    "    G.add_edge(row['artist_1'], row['artist_2'], weight=row['count'])\n",
    "\n",
    "# 3. Calculate participation coefficient and betweenness for artist network\n",
    "partition = community_louvain.best_partition(G, weight='weight')\n",
    "def participation_coefficient(G, partition):\n",
    "    pc = {}\n",
    "    for node in G.nodes():\n",
    "        comm = partition[node]\n",
    "        deg = G.degree(node)\n",
    "        if deg == 0:\n",
    "            pc[node] = 0\n",
    "            continue\n",
    "        comm_deg = Counter()\n",
    "        for nbr in G.neighbors(node):\n",
    "            nbr_comm = partition[nbr]\n",
    "            comm_deg[nbr_comm] += 1\n",
    "        sum_sq = sum((count/deg)**2 for count in comm_deg.values())\n",
    "        pc[node] = 1 - sum_sq\n",
    "    return pc\n",
    "pc_artist = participation_coefficient(G, partition)\n",
    "bc_artist = nx.betweenness_centrality(G, weight='weight')\n",
    "\n",
    "# 4. Build genre collaboration network\n",
    "genre_G = nx.Graph()\n",
    "for _, row in edges.iterrows():\n",
    "    a1, a2, count = row['artist_1'], row['artist_2'], row['count']\n",
    "    genres1 = artist_genre_map.get(a1, '')\n",
    "    genres2 = artist_genre_map.get(a2, '')\n",
    "    if isinstance(genres1, str):\n",
    "        genres1 = [g.strip().strip(\"'[]\") for g in genres1.split(',') if g.strip()]\n",
    "    if isinstance(genres2, str):\n",
    "        genres2 = [g.strip().strip(\"'[]\") for g in genres2.split(',') if g.strip()]\n",
    "    for g1 in genres1:\n",
    "        for g2 in genres2:\n",
    "            if not g1 or not g2:\n",
    "                continue\n",
    "            edge = tuple(sorted([g1, g2]))\n",
    "            if genre_G.has_edge(*edge):\n",
    "                genre_G[edge[0]][edge[1]]['weight'] += int(count)\n",
    "            else:\n",
    "                genre_G.add_edge(edge[0], edge[1], weight=int(count))\n",
    "\n",
    "# 5. Calculate participation coefficient and betweenness for genre network\n",
    "partition_genre = community_louvain.best_partition(genre_G, weight='weight')\n",
    "pc_genre = participation_coefficient(genre_G, partition_genre)\n",
    "bc_genre = nx.betweenness_centrality(genre_G, weight='weight')\n",
    "\n",
    "# 6. Select hub/bridge genres (top 10% by participation coefficient or betweenness)\n",
    "pc_thr = pd.Series(pc_genre).quantile(0.9)\n",
    "bc_thr = pd.Series(bc_genre).quantile(0.9)\n",
    "hub_bridge_genres = {g for g in genre_G.nodes() if pc_genre[g] > pc_thr or bc_genre[g] > bc_thr}\n",
    "\n",
    "# 7. Identify central artists\n",
    "# - Artists in the top 10% for participation or betweenness in the artist network\n",
    "pc_thr_a = pd.Series(pc_artist).quantile(0.9)\n",
    "bc_thr_a = pd.Series(bc_artist).quantile(0.9)\n",
    "hub_bridge_artists = [a for a in G.nodes() if pc_artist[a] > pc_thr_a or bc_artist[a] > bc_thr_a]\n",
    "\n",
    "# - Among these, artists with at least one genre in the hub/bridge genre set\n",
    "central_artists_2017 = []\n",
    "for a in hub_bridge_artists:\n",
    "    genres = artist_genre_map.get(a, '')\n",
    "    if isinstance(genres, str):\n",
    "        genres = [g.strip().strip(\"'[]\") for g in genres.split(',') if g.strip()]\n",
    "    if any(g in hub_bridge_genres for g in genres):\n",
    "        central_artists_2017.append(a)\n",
    "\n",
    "# 8. Output results\n",
    "print(\"Artists who played a central (hub/bridge) role in both artist and genre collaboration networks (2017):\")\n",
    "for a in central_artists_2017:\n",
    "    print(f\"- {a} | genres: {artist_genre_map.get(a, '')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zd1rz40qY695",
    "outputId": "0469a683-b5eb-4c29-f9a0-8f7db42abb11"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "from collections import Counter\n",
    "\n",
    "# 1. Load artist information\n",
    "artists_info = pd.read_csv('/content/spotify_artists_info_complete.csv', sep='\\t', encoding='utf-8')\n",
    "artists_info = artists_info.drop_duplicates(subset=['name'], keep='first')\n",
    "artist_genre_map = artists_info.set_index('name')['genres'].to_dict()\n",
    "\n",
    "# 2. Build artist collaboration network\n",
    "edges = pd.read_csv('/content/global-artist_network-2018.csv', sep='\\t', engine='python', quoting=3)\n",
    "edges = edges[['artist_1', 'artist_2', 'count']].dropna()\n",
    "edges['count'] = pd.to_numeric(edges['count'], errors='coerce').fillna(1).astype(int)\n",
    "G = nx.Graph()\n",
    "for _, row in edges.iterrows():\n",
    "    G.add_edge(row['artist_1'], row['artist_2'], weight=row['count'])\n",
    "\n",
    "# 3. Calculate participation coefficient and betweenness for artist network\n",
    "partition = community_louvain.best_partition(G, weight='weight')\n",
    "def participation_coefficient(G, partition):\n",
    "    pc = {}\n",
    "    for node in G.nodes():\n",
    "        comm = partition[node]\n",
    "        deg = G.degree(node)\n",
    "        if deg == 0:\n",
    "            pc[node] = 0\n",
    "            continue\n",
    "        comm_deg = Counter()\n",
    "        for nbr in G.neighbors(node):\n",
    "            nbr_comm = partition[nbr]\n",
    "            comm_deg[nbr_comm] += 1\n",
    "        sum_sq = sum((count/deg)**2 for count in comm_deg.values())\n",
    "        pc[node] = 1 - sum_sq\n",
    "    return pc\n",
    "pc_artist = participation_coefficient(G, partition)\n",
    "bc_artist = nx.betweenness_centrality(G, weight='weight')\n",
    "\n",
    "# 4. Build genre collaboration network\n",
    "genre_G = nx.Graph()\n",
    "for _, row in edges.iterrows():\n",
    "    a1, a2, count = row['artist_1'], row['artist_2'], row['count']\n",
    "    genres1 = artist_genre_map.get(a1, '')\n",
    "    genres2 = artist_genre_map.get(a2, '')\n",
    "    if isinstance(genres1, str):\n",
    "        genres1 = [g.strip().strip(\"'[]\") for g in genres1.split(',') if g.strip()]\n",
    "    if isinstance(genres2, str):\n",
    "        genres2 = [g.strip().strip(\"'[]\") for g in genres2.split(',') if g.strip()]\n",
    "    for g1 in genres1:\n",
    "        for g2 in genres2:\n",
    "            if not g1 or not g2:\n",
    "                continue\n",
    "            edge = tuple(sorted([g1, g2]))\n",
    "            if genre_G.has_edge(*edge):\n",
    "                genre_G[edge[0]][edge[1]]['weight'] += int(count)\n",
    "            else:\n",
    "                genre_G.add_edge(edge[0], edge[1], weight=int(count))\n",
    "\n",
    "# 5. Calculate participation coefficient and betweenness for genre network\n",
    "partition_genre = community_louvain.best_partition(genre_G, weight='weight')\n",
    "pc_genre = participation_coefficient(genre_G, partition_genre)\n",
    "bc_genre = nx.betweenness_centrality(genre_G, weight='weight')\n",
    "\n",
    "# 6. Select hub/bridge genres (top 10% by participation coefficient or betweenness)\n",
    "pc_thr = pd.Series(pc_genre).quantile(0.9)\n",
    "bc_thr = pd.Series(bc_genre).quantile(0.9)\n",
    "hub_bridge_genres = {g for g in genre_G.nodes() if pc_genre[g] > pc_thr or bc_genre[g] > bc_thr}\n",
    "\n",
    "# 7. Identify central artists\n",
    "# - Artists in the top 10% for participation or betweenness in the artist network\n",
    "pc_thr_a = pd.Series(pc_artist).quantile(0.9)\n",
    "bc_thr_a = pd.Series(bc_artist).quantile(0.9)\n",
    "hub_bridge_artists = [a for a in G.nodes() if pc_artist[a] > pc_thr_a or bc_artist[a] > bc_thr_a]\n",
    "\n",
    "# - Among these, artists with at least one genre in the hub/bridge genre set\n",
    "central_artists_2018 = []\n",
    "for a in hub_bridge_artists:\n",
    "    genres = artist_genre_map.get(a, '')\n",
    "    if isinstance(genres, str):\n",
    "        genres = [g.strip().strip(\"'[]\") for g in genres.split(',') if g.strip()]\n",
    "    if any(g in hub_bridge_genres for g in genres):\n",
    "        central_artists_2018.append(a)\n",
    "\n",
    "# 8. Output results\n",
    "print(\"Artists who played a central (hub/bridge) role in both artist and genre collaboration networks (2018):\")\n",
    "for a in central_artists_2018:\n",
    "    print(f\"- {a} | genres: {artist_genre_map.get(a, '')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_jDi_xD3ZFdp",
    "outputId": "add4569e-7c89-4084-ffea-69d622a0f5e0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "from collections import Counter\n",
    "\n",
    "# 1. Load artist information\n",
    "artists_info = pd.read_csv('/content/spotify_artists_info_complete.csv', sep='\\t', encoding='utf-8')\n",
    "artists_info = artists_info.drop_duplicates(subset=['name'], keep='first')\n",
    "artist_genre_map = artists_info.set_index('name')['genres'].to_dict()\n",
    "\n",
    "# 2. Build artist collaboration network\n",
    "edges = pd.read_csv('/content/global-artist_network-2019.csv', sep='\\t', engine='python', quoting=3)\n",
    "edges = edges[['artist_1', 'artist_2', 'count']].dropna()\n",
    "edges['count'] = pd.to_numeric(edges['count'], errors='coerce').fillna(1).astype(int)\n",
    "G = nx.Graph()\n",
    "for _, row in edges.iterrows():\n",
    "    G.add_edge(row['artist_1'], row['artist_2'], weight=row['count'])\n",
    "\n",
    "# 3. Calculate participation coefficient and betweenness for artist network\n",
    "partition = community_louvain.best_partition(G, weight='weight')\n",
    "def participation_coefficient(G, partition):\n",
    "    pc = {}\n",
    "    for node in G.nodes():\n",
    "        comm = partition[node]\n",
    "        deg = G.degree(node)\n",
    "        if deg == 0:\n",
    "            pc[node] = 0\n",
    "            continue\n",
    "        comm_deg = Counter()\n",
    "        for nbr in G.neighbors(node):\n",
    "            nbr_comm = partition[nbr]\n",
    "            comm_deg[nbr_comm] += 1\n",
    "        sum_sq = sum((count/deg)**2 for count in comm_deg.values())\n",
    "        pc[node] = 1 - sum_sq\n",
    "    return pc\n",
    "pc_artist = participation_coefficient(G, partition)\n",
    "bc_artist = nx.betweenness_centrality(G, weight='weight')\n",
    "\n",
    "# 4. Build genre collaboration network\n",
    "genre_G = nx.Graph()\n",
    "for _, row in edges.iterrows():\n",
    "    a1, a2, count = row['artist_1'], row['artist_2'], row['count']\n",
    "    genres1 = artist_genre_map.get(a1, '')\n",
    "    genres2 = artist_genre_map.get(a2, '')\n",
    "    if isinstance(genres1, str):\n",
    "        genres1 = [g.strip().strip(\"'[]\") for g in genres1.split(',') if g.strip()]\n",
    "    if isinstance(genres2, str):\n",
    "        genres2 = [g.strip().strip(\"'[]\") for g in genres2.split(',') if g.strip()]\n",
    "    for g1 in genres1:\n",
    "        for g2 in genres2:\n",
    "            if not g1 or not g2:\n",
    "                continue\n",
    "            edge = tuple(sorted([g1, g2]))\n",
    "            if genre_G.has_edge(*edge):\n",
    "                genre_G[edge[0]][edge[1]]['weight'] += int(count)\n",
    "            else:\n",
    "                genre_G.add_edge(edge[0], edge[1], weight=int(count))\n",
    "\n",
    "# 5. Calculate participation coefficient and betweenness for genre network\n",
    "partition_genre = community_louvain.best_partition(genre_G, weight='weight')\n",
    "pc_genre = participation_coefficient(genre_G, partition_genre)\n",
    "bc_genre = nx.betweenness_centrality(genre_G, weight='weight')\n",
    "\n",
    "# 6. Select hub/bridge genres (top 10% by participation coefficient or betweenness)\n",
    "pc_thr = pd.Series(pc_genre).quantile(0.9)\n",
    "bc_thr = pd.Series(bc_genre).quantile(0.9)\n",
    "hub_bridge_genres = {g for g in genre_G.nodes() if pc_genre[g] > pc_thr or bc_genre[g] > bc_thr}\n",
    "\n",
    "# 7. Identify central artists\n",
    "# - Artists in the top 10% for participation or betweenness in the artist network\n",
    "pc_thr_a = pd.Series(pc_artist).quantile(0.9)\n",
    "bc_thr_a = pd.Series(bc_artist).quantile(0.9)\n",
    "hub_bridge_artists = [a for a in G.nodes() if pc_artist[a] > pc_thr_a or bc_artist[a] > bc_thr_a]\n",
    "\n",
    "# - Among these, artists with at least one genre in the hub/bridge genre set\n",
    "central_artists_2019 = []\n",
    "for a in hub_bridge_artists:\n",
    "    genres = artist_genre_map.get(a, '')\n",
    "    if isinstance(genres, str):\n",
    "        genres = [g.strip().strip(\"'[]\") for g in genres.split(',') if g.strip()]\n",
    "    if any(g in hub_bridge_genres for g in genres):\n",
    "        central_artists_2019.append(a)\n",
    "\n",
    "# 8. Output results\n",
    "print(\"Artists who played a central (hub/bridge) role in both artist and genre collaboration networks (2019):\")\n",
    "for a in central_artists_2019:\n",
    "    print(f\"- {a} | genres: {artist_genre_map.get(a, '')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KPqbysP6ZREm",
    "outputId": "0efe4643-c784-4b7e-8895-2dd4c8569c13"
   },
   "outputs": [],
   "source": [
    "# Prepare sets of central artists for each year (using previous analysis results)\n",
    "central_artists_2017 = set(central_artists_2017)\n",
    "central_artists_2018 = set(central_artists_2018)\n",
    "central_artists_2019 = set(central_artists_2019)\n",
    "\n",
    "# Extract only artists who were central in all three years\n",
    "central_all_years = central_artists_2017 & central_artists_2018 & central_artists_2019\n",
    "\n",
    "# Sort the result as a list\n",
    "central_all_years_list = sorted(list(central_all_years))\n",
    "\n",
    "print(\"Artists who played a central (bridge/hub) role in all of 2017, 2018, and 2019:\")\n",
    "for artist in central_all_years_list:\n",
    "    print(\"-\", artist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "id": "4Jk87crhZ4Hv",
    "outputId": "94580209-cedb-4121-c8fd-374d7be996d3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load artist info\n",
    "artists_info = pd.read_csv('spotify_artists_info_complete.csv', sep='\\t', encoding='utf-8')\n",
    "artists_info = artists_info.drop_duplicates(subset=['name'], keep='first')\n",
    "info_map = artists_info.set_index('name').to_dict('index')\n",
    "\n",
    "# Assume central_all_years_list is already defined as a list of artist names\n",
    "# Example:\n",
    "# central_all_years_list = ['Anitta', 'Bebe Rexha', 'Camila Cabello', ...]\n",
    "\n",
    "# Collect info for each central artist\n",
    "central_artists_data = []\n",
    "for artist in central_all_years_list:\n",
    "    info = info_map.get(artist, {})\n",
    "    central_artists_data.append({\n",
    "        'artist': artist,\n",
    "        'genres': info.get('genres', ''),\n",
    "        'followers': info.get('followers', ''),\n",
    "        'popularity': info.get('popularity', '')\n",
    "    })\n",
    "\n",
    "# Create DataFrame and sort by popularity\n",
    "central_artists_df = pd.DataFrame(central_artists_data)\n",
    "central_artists_df = central_artists_df.sort_values(by='popularity', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "from IPython.display import display\n",
    "display(central_artists_df[['artist', 'genres', 'followers', 'popularity']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxR3lL8UcCly"
   },
   "source": [
    "## Emerging Genre Community Detection + Central Artists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilAJ-ysecA83",
    "outputId": "10b567db-8d5b-4a7c-cbe6-6076adc46159"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "from collections import Counter\n",
    "\n",
    "# Network file paths by year\n",
    "files = {\n",
    "    2017: 'global-artist_network-2017.csv',\n",
    "    2018: 'global-artist_network-2018.csv',\n",
    "    2019: 'global-artist_network-2019.csv'\n",
    "}\n",
    "\n",
    "# Load artist information\n",
    "artists_info = pd.read_csv('spotify_artists_info_complete.csv', sep='\\t', encoding='utf-8')\n",
    "artists_info = artists_info.drop_duplicates(subset=['name'], keep='first')\n",
    "artist_genre_map = artists_info.set_index('name')['genres'].to_dict()\n",
    "\n",
    "# 1. Aggregate degree by community for each year\n",
    "community_degree_time = {}\n",
    "for year, path in files.items():\n",
    "    df = pd.read_csv(path, sep='\\t', engine='python', quoting=3)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    edges = df[['artist_1', 'artist_2', 'count']].dropna()\n",
    "    edges['count'] = pd.to_numeric(edges['count'], errors='coerce').fillna(1).astype(int)\n",
    "    G = nx.Graph()\n",
    "    for _, row in edges.iterrows():\n",
    "        G.add_edge(row['artist_1'], row['artist_2'], weight=row['count'])\n",
    "    partition = community_louvain.best_partition(G, weight='weight')\n",
    "    degrees = dict(G.degree(weight='weight'))\n",
    "    comm_degree = {}\n",
    "    for comm in set(partition.values()):\n",
    "        nodes = [n for n, c in partition.items() if c == comm]\n",
    "        deg_sum = sum(dict(G.degree(nodes, weight='weight')).values())\n",
    "        comm_degree[comm] = deg_sum\n",
    "    community_degree_time[year] = comm_degree\n",
    "\n",
    "# 2. Integrate community indices and convert to DataFrame\n",
    "all_communities = set()\n",
    "for comms in community_degree_time.values():\n",
    "    all_communities.update(comms.keys())\n",
    "all_communities = list(all_communities)\n",
    "\n",
    "degree_data = {}\n",
    "for year in files.keys():\n",
    "    degree_data[year] = [community_degree_time[year].get(comm, 0) for comm in all_communities]\n",
    "degree_df = pd.DataFrame(degree_data, index=all_communities)\n",
    "\n",
    "# 3. Add columns for year-over-year change\n",
    "degree_df['diff_18_17'] = degree_df[2018] - degree_df[2017]\n",
    "degree_df['diff_19_18'] = degree_df[2019] - degree_df[2018]\n",
    "\n",
    "# Relaxed condition: 2017 degree ≤ 100, and (2018-2017 > 200) or (2019-2018 > 200)\n",
    "emerging = degree_df[(degree_df[2017] <= 100) & ((degree_df['diff_18_17'] > 200) | (degree_df['diff_19_18'] > 200))]\n",
    "emerging = emerging.sort_values(['diff_18_17', 'diff_19_18'], ascending=False)\n",
    "\n",
    "print(\"Emerging genre communities:\")\n",
    "print(emerging[[2017, 2018, 2019, 'diff_18_17', 'diff_19_18']])\n",
    "\n",
    "# 4. Function to find top genres and central artist for emerging communities\n",
    "def get_community_detail(year, comm):\n",
    "    df = pd.read_csv(files[year], sep='\\t', engine='python', quoting=3)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    edges = df[['artist_1', 'artist_2', 'count']].dropna()\n",
    "    edges['count'] = pd.to_numeric(edges['count'], errors='coerce').fillna(1).astype(int)\n",
    "    G = nx.Graph()\n",
    "    for _, row in edges.iterrows():\n",
    "        G.add_edge(row['artist_1'], row['artist_2'], weight=row['count'])\n",
    "    partition = community_louvain.best_partition(G, weight='weight')\n",
    "    degrees = dict(G.degree(weight='weight'))\n",
    "    comm_nodes = [n for n, c in partition.items() if c == comm]\n",
    "    genres = []\n",
    "    for n in comm_nodes:\n",
    "        g = artist_genre_map.get(n)\n",
    "        if isinstance(g, str):\n",
    "            genres.extend([x.strip() for x in g.replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace('\"', '').split(',') if x.strip()])\n",
    "    genre_counts = Counter(genres)\n",
    "    top_genres = genre_counts.most_common(5)\n",
    "    if comm_nodes:\n",
    "        rep_artist = max(comm_nodes, key=lambda n: degrees.get(n, 0))\n",
    "    else:\n",
    "        rep_artist = None\n",
    "    return top_genres, rep_artist\n",
    "\n",
    "print(\"\\nEmerging communities (2019) - Top genres and central artist:\")\n",
    "for comm in emerging.index:\n",
    "    top_genres, rep_artist = get_community_detail(2019, comm)\n",
    "    print(f\"- Community {comm}:\")\n",
    "    print(f\"  Top 5 genres: {top_genres}\")\n",
    "    print(f\"  Central artist: {rep_artist}\")\n",
    "    if rep_artist:\n",
    "        genres = artist_genre_map.get(rep_artist, '')\n",
    "        print(f\"    (Genres: {genres})\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
