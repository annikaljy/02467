{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlT8BAcg35Wb",
        "outputId": "8c920aae-80b9-45ee-b61f-4f2f0a84e16e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "A total of 1484 unique researcher names have been extracted.\n",
            "Results have been saved to /content/drive/MyDrive/ic2s2_2023_researchers.txt and /content/drive/MyDrive/ic2s2_2023_researchers.csv.\n"
          ]
        }
      ],
      "source": [
        "# Week 1 - Web Scraping Q1\n",
        "\n",
        "from google.colab import drive\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def clean_name(name):\n",
        "    # Clean name - remove special characters and unnecessary whitespace\n",
        "    name = re.sub(r'[,\\n\\t\\r]', '', name)\n",
        "    name = re.sub(r'\\s+', ' ', name)\n",
        "    name = name.strip()\n",
        "\n",
        "    # Remove <u> tags\n",
        "    name = re.sub(r'</?u>', '', name)\n",
        "\n",
        "    # Exclude names that are too short or contain digits\n",
        "    if len(name) < 2 or bool(re.search(r'\\d', name)):\n",
        "        return None\n",
        "\n",
        "    return name\n",
        "\n",
        "def extract_names_from_text(text):\n",
        "    # Extract names from text\n",
        "    # Create an empty list to hold names\n",
        "    name_list = []\n",
        "\n",
        "    # Handle authors list separated by commas\n",
        "    if ',' in text:\n",
        "        author_list = text.split(',')\n",
        "        for author in author_list:\n",
        "            name = clean_name(author)\n",
        "            if name:\n",
        "                name_list.append(name)\n",
        "    else:\n",
        "        name = clean_name(text)\n",
        "        if name:\n",
        "            name_list.append(name)\n",
        "\n",
        "    return name_list\n",
        "\n",
        "def parse_html_for_names(html_content):\n",
        "    # Extract all researcher names from HTML\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    # Remove duplicates\n",
        "    name_list_to_set = set()\n",
        "\n",
        "    # Find all list items containing presentation titles and author information\n",
        "    for li in soup.find_all('li'):\n",
        "        text = li.get_text()\n",
        "        if not text:\n",
        "            continue\n",
        "\n",
        "        # Find <i> tags containing author information\n",
        "        authors_tag = li.find('i')\n",
        "        if authors_tag:\n",
        "            authors_text = authors_tag.get_text()\n",
        "            name_list = extract_names_from_text(authors_text)\n",
        "            name_list_to_set.update(name_list)\n",
        "\n",
        "    # Find session chairs\n",
        "    chair_patterns = soup.find_all(string=re.compile(r'Chair:', re.IGNORECASE))\n",
        "    for pattern in chair_patterns:\n",
        "        chair_text = pattern.strip()\n",
        "        if 'Chair:' in chair_text:\n",
        "            chair_name = chair_text.split('Chair:')[1]\n",
        "            name = clean_name(chair_name)\n",
        "            if name:\n",
        "                name_list_to_set.add(name)\n",
        "\n",
        "    return sorted(list(name_list_to_set))\n",
        "\n",
        "def main():\n",
        "    # Set HTML file path (Google Drive path)\n",
        "    file_path = '/content/drive/MyDrive/IC2S2_2023.html'\n",
        "    # Alternatively, URL can be used directly\n",
        "\n",
        "    # Read HTML file\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        html_content = f.read()\n",
        "\n",
        "    # Extract names\n",
        "    names = parse_html_for_names(html_content)\n",
        "\n",
        "    # Save results to file\n",
        "    output_path = '/content/drive/MyDrive/ic2s2_2023_researchers.txt'\n",
        "    df_path = '/content/drive/MyDrive/ic2s2_2023_researchers.csv'\n",
        "\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        for name in names:\n",
        "            f.write(name + '\\n')\n",
        "\n",
        "    print(f\"A total of {len(names)} unique researcher names have been extracted.\")\n",
        "    print(f\"Results have been saved to {output_path} and {df_path}.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2\n",
        "\n",
        "!pip install fuzzywuzzy[speedup]\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from fuzzywuzzy import fuzz\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def extract_person_from_candidate(candidate):\n",
        "    \"\"\"\n",
        "    Since each cell entry is in the format \"Person Name, Other Information\",\n",
        "    extract the text before the first comma as the person's name.\n",
        "    If an affiliation in parentheses is present, remove the parentheses and its content.\n",
        "\n",
        "    Example:\n",
        "      \"Chris Kempes, ...\"                  -> \"Chris Kempes\"\n",
        "      \"Chris Kempes (Santa Fe Institute)\"  -> \"Chris Kempes\"\n",
        "    \"\"\"\n",
        "    candidate = candidate.strip()\n",
        "    # If there is a comma, use the text before the first comma; otherwise, use the entire text\n",
        "    if ',' in candidate:\n",
        "        person = candidate.split(',', 1)[0]\n",
        "    else:\n",
        "        person = candidate\n",
        "    # Remove parentheses and the text within\n",
        "    person = re.sub(r'\\s*\\(.*?\\)', '', person)\n",
        "    return person.strip()\n",
        "\n",
        "def extract_names_from_cell(cell):\n",
        "    \"\"\"\n",
        "    Assumes the cell text is in the format \"Person Name, Other Information; Person Name, Other Information; ...\"\n",
        "    Splits the string by semicolons (;) and applies extract_person_from_candidate on each entry.\n",
        "    Returns only those names that consist of two or more words.\n",
        "    \"\"\"\n",
        "    names = []\n",
        "    parts = cell.split(';')\n",
        "    for part in parts:\n",
        "        part = part.strip()\n",
        "        if not part:\n",
        "            continue\n",
        "        person_name = extract_person_from_candidate(part)\n",
        "        if len(person_name.split()) >= 2:\n",
        "            names.append(person_name)\n",
        "    return names\n",
        "\n",
        "def extract_names_from_df(df, column_name):\n",
        "    \"\"\"\n",
        "    From the specified column (e.g., 'Poster authors' or 'Presentation authors') of the given DataFrame,\n",
        "    apply extract_names_from_cell() to extract all candidate person names.\n",
        "    \"\"\"\n",
        "    authors = []\n",
        "    if column_name in df.columns:\n",
        "        for entry in df[column_name].dropna():\n",
        "            authors.extend(extract_names_from_cell(entry))\n",
        "    else:\n",
        "        print(f\"Column '{column_name}' does not exist. Available columns: {df.columns.tolist()}\")\n",
        "    return authors\n",
        "\n",
        "def cluster_names(names, threshold=90):\n",
        "    \"\"\"\n",
        "    Uses fuzzywuzzy's token_sort_ratio to group names that have a similarity score above the threshold,\n",
        "    considering them as the same individual. Within each cluster, the shortest (cleanest) version of the name\n",
        "    is selected as the representative.\n",
        "\n",
        "    Returns:\n",
        "      representative_names: Final list of unique person names\n",
        "      clusters: List of names for each cluster (for debugging)\n",
        "    \"\"\"\n",
        "    names_list = list(set(names))\n",
        "    clusters = []\n",
        "    used = set()\n",
        "    for i, name in enumerate(names_list):\n",
        "        if name in used:\n",
        "            continue\n",
        "        cluster = [name]\n",
        "        used.add(name)\n",
        "        for other in names_list[i+1:]:\n",
        "            if other in used:\n",
        "                continue\n",
        "            score = fuzz.token_sort_ratio(name, other)\n",
        "            if score >= threshold:\n",
        "                cluster.append(other)\n",
        "                used.add(other)\n",
        "        clusters.append(cluster)\n",
        "    representative_names = [min(cluster, key=len) for cluster in clusters]\n",
        "    return representative_names, clusters\n",
        "\n",
        "def main():\n",
        "    # Set CSV file paths (using actual Google Drive paths)\n",
        "    poster_csv    = '/content/drive/MyDrive/IC2S2_2024_posters.csv'\n",
        "    lightning_csv = '/content/drive/MyDrive/IC2S2_2024_lightning_talks.csv'\n",
        "    orals_csv     = '/content/drive/MyDrive/IC2S2_2024_oral_panels.csv'\n",
        "\n",
        "    # Read CSV files\n",
        "    posters_df   = pd.read_csv(poster_csv)\n",
        "    lightning_df = pd.read_csv(lightning_csv)\n",
        "    orals_df     = pd.read_csv(orals_csv)\n",
        "\n",
        "    # Extract candidate names from the author columns of each DataFrame\n",
        "    poster_authors      = extract_names_from_df(posters_df, 'Poster authors')\n",
        "    lightning_authors   = extract_names_from_df(lightning_df, 'Presentation authors')\n",
        "    orals_authors       = extract_names_from_df(orals_df, 'Presentation authors')\n",
        "\n",
        "    # Combine the results from all three files\n",
        "    all_authors = poster_authors + lightning_authors + orals_authors\n",
        "    print(\"Total extracted candidate count (including duplicates):\", len(all_authors))\n",
        "\n",
        "    # Remove duplicates\n",
        "    unique_authors = list(set(all_authors))\n",
        "    print(\"Unique candidate count after removing duplicates:\", len(unique_authors))\n",
        "\n",
        "    # Use fuzzy matching to group slightly variant names and select representative names\n",
        "    final_names, clusters = cluster_names(unique_authors, threshold=90)\n",
        "    final_names = sorted(final_names)\n",
        "\n",
        "    # Set the output file path for the results\n",
        "    output_path = '/content/drive/MyDrive/IC2S2_2024_final_person_names_from_csv.txt'\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        for name in final_names:\n",
        "            f.write(name + \"\\n\")\n",
        "\n",
        "    print(\"Final unique person name count:\", len(final_names))\n",
        "    print(\"Result file saved at:\", output_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwX5_8ki6MSg",
        "outputId": "700a9140-2056-4f56-d3be-201616dba8ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy[speedup]\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting python-levenshtein>=0.12 (from fuzzywuzzy[speedup])\n",
            "  Downloading python_Levenshtein-0.26.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Levenshtein==0.26.1 (from python-levenshtein>=0.12->fuzzywuzzy[speedup])\n",
            "  Downloading levenshtein-0.26.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.1->python-levenshtein>=0.12->fuzzywuzzy[speedup])\n",
            "  Downloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading python_Levenshtein-0.26.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.26.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.7/162.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fuzzywuzzy, rapidfuzz, Levenshtein, python-levenshtein\n",
            "Successfully installed Levenshtein-0.26.1 fuzzywuzzy-0.18.0 python-levenshtein-0.26.1 rapidfuzz-3.12.1\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Total extracted candidate count (including duplicates): 1790\n",
            "Unique candidate count after removing duplicates: 1227\n",
            "Final unique person name count: 1220\n",
            "Result file saved at: /content/drive/MyDrive/IC2S2_2024_final_person_names_from_csv.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Aggregated Names with fuzzywuzzy\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from fuzzywuzzy import fuzz\n",
        "from collections import defaultdict\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def extract_person_from_candidate(candidate):\n",
        "    \"\"\"\n",
        "    Since each cell entry is formatted as \"Person Name, Other Information\",\n",
        "    extract the text before the first comma as the person's name,\n",
        "    and if an affiliation in parentheses exists, remove it.\n",
        "    \"\"\"\n",
        "    candidate = candidate.strip()\n",
        "    if ',' in candidate:\n",
        "        person = candidate.split(',', 1)[0]\n",
        "    else:\n",
        "        person = candidate\n",
        "    # Remove parentheses and the text within\n",
        "    person = re.sub(r'\\s*\\(.*?\\)', '', person)\n",
        "    return person.strip()\n",
        "\n",
        "def extract_names_from_cell(cell):\n",
        "    \"\"\"\n",
        "    Assumes that the cell text is in the format \"Person Name, Other Information; Person Name, Other Information; ...\"\n",
        "    Splits the text by semicolons (;) and applies the extract_person_from_candidate function to each part.\n",
        "    \"\"\"\n",
        "    names = []\n",
        "    parts = cell.split(';')\n",
        "    for part in parts:\n",
        "        part = part.strip()\n",
        "        if not part:\n",
        "            continue\n",
        "        person_name = extract_person_from_candidate(part)\n",
        "        if len(person_name.split()) >= 2:  # Assume a valid person name has at least two words\n",
        "            names.append(person_name)\n",
        "    return names\n",
        "\n",
        "def extract_names_from_df(df, column_name):\n",
        "    \"\"\"\n",
        "    From the specified column (e.g., 'Poster authors' or 'Presentation authors') of the given DataFrame,\n",
        "    apply extract_names_from_cell() on each cell to extract all candidate person names.\n",
        "    \"\"\"\n",
        "    authors = []\n",
        "    if column_name in df.columns:\n",
        "        for entry in df[column_name].dropna():\n",
        "            authors.extend(extract_names_from_cell(entry))\n",
        "    else:\n",
        "        print(f\"Column '{column_name}' does not exist. Available columns: {df.columns.tolist()}\")\n",
        "    return authors\n",
        "\n",
        "def cluster_names_with_logging(names, threshold=90):\n",
        "    \"\"\"\n",
        "    Uses fuzzywuzzy to group names with a similarity score above the threshold,\n",
        "    treating them as the same individual. Within each cluster, the shortest name is selected\n",
        "    as the representative, and the merged names are logged.\n",
        "\n",
        "    Returns:\n",
        "      representative_names: Final list of unique person names.\n",
        "      clusters: List of names within each cluster (for debugging).\n",
        "      merge_log: Dictionary mapping representative names to the merged names.\n",
        "    \"\"\"\n",
        "    names_list = list(set(names))  # Remove duplicates\n",
        "    clusters = []\n",
        "    used = set()\n",
        "    merge_log = defaultdict(list)  # Log for merged names\n",
        "\n",
        "    for i, name in enumerate(names_list):\n",
        "        if name in used:\n",
        "            continue\n",
        "        cluster = [name]\n",
        "        used.add(name)\n",
        "        for other in names_list[i+1:]:\n",
        "            if other in used:\n",
        "                continue\n",
        "            score = fuzz.token_sort_ratio(name, other)\n",
        "            if score >= threshold:\n",
        "                cluster.append(other)\n",
        "                used.add(other)\n",
        "        clusters.append(cluster)\n",
        "        representative_name = min(cluster, key=len)  # Select the shortest name as the representative\n",
        "        for merged_name in cluster:\n",
        "            if merged_name != representative_name:\n",
        "                merge_log[representative_name].append(merged_name)\n",
        "\n",
        "    representative_names = [min(cluster, key=len) for cluster in clusters]\n",
        "    return representative_names, clusters, merge_log\n",
        "\n",
        "def print_merge_results(merge_log):\n",
        "    \"\"\"A function to neatly print the merge results.\"\"\"\n",
        "    print(\"\\n=== Merged Names Results ===\")\n",
        "    for representative, merged_names in merge_log.items():\n",
        "        if merged_names:  # Only print if there are merged names\n",
        "            print(f\"\\nRepresentative Name: {representative}\")\n",
        "            print(f\"Merged Names: {', '.join(merged_names)}\")\n",
        "    print(\"\\n============================\")\n",
        "\n",
        "def main():\n",
        "    # Set CSV file paths (using paths in Google Drive)\n",
        "    poster_csv = '/content/drive/MyDrive/IC2S2_2024_posters.csv'\n",
        "    lightning_csv = '/content/drive/MyDrive/IC2S2_2024_lightning_talks.csv'\n",
        "    orals_csv = '/content/drive/MyDrive/IC2S2_2024_oral_panels.csv'\n",
        "\n",
        "    # Read the CSV files\n",
        "    posters_df = pd.read_csv(poster_csv)\n",
        "    lightning_df = pd.read_csv(lightning_csv)\n",
        "    orals_df = pd.read_csv(orals_csv)\n",
        "\n",
        "    # Extract candidate person names from the author columns of each DataFrame\n",
        "    poster_authors = extract_names_from_df(posters_df, 'Poster authors')\n",
        "    lightning_authors = extract_names_from_df(lightning_df, 'Presentation authors')\n",
        "    orals_authors = extract_names_from_df(orals_df, 'Presentation authors')\n",
        "\n",
        "    # Combine the results from all three files\n",
        "    all_authors = poster_authors + lightning_authors + orals_authors\n",
        "\n",
        "    # Remove duplicates and use fuzzy matching to group similar names, logging the merges\n",
        "    final_names, clusters, merge_log = cluster_names_with_logging(all_authors, threshold=90)\n",
        "\n",
        "    # Print the merge results\n",
        "    print_merge_results(merge_log)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjdoQrkT6UgO",
        "outputId": "9d5235c4-f04d-4d59-c508-5eef9f7029c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "=== Merged Names Results ===\n",
            "\n",
            "Representative Name: Ho Chun Herbert Chang\n",
            "Merged Names: Ho-Chun Herbert Chang\n",
            "\n",
            "Representative Name: Zou Yang\n",
            "Merged Names: Yang Zhou\n",
            "\n",
            "Representative Name: Yan Jiang\n",
            "Merged Names: Yanru Jiang\n",
            "\n",
            "Representative Name: Matthew F Asher\n",
            "Merged Names: Dr Matthew F Asher\n",
            "\n",
            "Representative Name: Nicolò Alessandro Girardini\n",
            "Merged Names: Nicolas Alessandro Girardini\n",
            "\n",
            "Representative Name: Yifan Wang\n",
            "Merged Names: Yifang Wang\n",
            "\n",
            "Representative Name: Eduardo López\n",
            "Merged Names: Eduardo LÃ³pez\n",
            "\n",
            "============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3\n",
        "\n",
        "import os\n",
        "\n",
        "# File paths for 2023 and 2024 (using the paths saved from previous code)\n",
        "file_2023 = '/content/drive/MyDrive/ic2s2_2023_researchers.txt'\n",
        "file_2024 = '/content/drive/MyDrive/IC2S2_2024_final_person_names_from_csv.txt'\n",
        "\n",
        "# Check if the files exist\n",
        "if os.path.exists(file_2023):\n",
        "    print(\"The 2023 file exists:\", file_2023)\n",
        "else:\n",
        "    print(\"The 2023 file does not exist. Please check the path:\", file_2023)\n",
        "\n",
        "if os.path.exists(file_2024):\n",
        "    print(\"The 2024 file exists:\", file_2024)\n",
        "else:\n",
        "    print(\"The 2024 file does not exist. Please check the path:\", file_2024)\n",
        "\n",
        "# Load the researcher list for 2023\n",
        "with open(file_2023, 'r', encoding='utf-8') as f:\n",
        "    names_2023 = f.read().splitlines()\n",
        "set_2023 = set(names_2023)\n",
        "\n",
        "# Load the researcher list for 2024\n",
        "with open(file_2024, 'r', encoding='utf-8') as f:\n",
        "    names_2024 = f.read().splitlines()\n",
        "set_2024 = set(names_2024)\n",
        "\n",
        "# Calculate the intersection (common names) between the two files\n",
        "common_names = set_2023.intersection(set_2024)\n",
        "\n",
        "print(\"Both IC2S2 2023 and 2024 covered\", len(common_names), \"names.\")\n",
        "print(\"Common names:\")\n",
        "for name in sorted(common_names):\n",
        "    print(name)\n",
        "\n",
        "# Save the results to a text file on Google Drive\n",
        "output_txt = '/content/drive/MyDrive/IC2S2_Common_names.txt'\n",
        "with open(output_txt, 'w', encoding='utf-8') as f:\n",
        "    for name in sorted(common_names):\n",
        "        f.write(name + \"\\n\")\n",
        "print(\"The results have been saved to a text file:\", output_txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J95oLNlG6tZh",
        "outputId": "67f52730-2d25-42fd-d015-a031a2bd4715"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 2023 file exists: /content/drive/MyDrive/ic2s2_2023_researchers.txt\n",
            "The 2024 file exists: /content/drive/MyDrive/IC2S2_2024_final_person_names_from_csv.txt\n",
            "Both IC2S2 2023 and 2024 covered 286 names.\n",
            "Common names:\n",
            "Aaron Clauset\n",
            "Aaron Schein\n",
            "Abdullah Almaatouq\n",
            "Adam Stefkovics\n",
            "Agnieszka Czaplicka\n",
            "Akhil Arora\n",
            "Akira Matsui\n",
            "Albert-Laszlo Barabasi\n",
            "Alessandro Flammini\n",
            "Alessia Antelmi\n",
            "Alex Pentland\n",
            "Alexander J Gates\n",
            "Alexandra Segerberg\n",
            "Aliakbar Akbaritabar\n",
            "Alina Herderich\n",
            "Allison Koenecke\n",
            "Almog Simchon\n",
            "Amirhossein Nakhaei\n",
            "Anastasia Karpova\n",
            "Andrea Passerini\n",
            "Andreas Bjerre-Nielsen\n",
            "Andrew Renninger\n",
            "Andrés Gvirtz\n",
            "Angelita Repetto\n",
            "Anna Seo Gyeong Choi\n",
            "Anne-Marie Nussberger\n",
            "Antonio Longa\n",
            "Anubhab Das\n",
            "Arianna Pera\n",
            "Artem Kuriksha\n",
            "Ashton Anderson\n",
            "Attila Varga\n",
            "Ayan-Yue Gupta\n",
            "Babak Heydari\n",
            "Baird Howland\n",
            "Bao Tran Truong\n",
            "Bedoor AlShebli\n",
            "Belén C Saldías Fuentes\n",
            "Bernardo Garcia Bulle Bueno\n",
            "Bhargav Srinivasa Desikan\n",
            "Brenda Curtis\n",
            "Brendan O'Connor\n",
            "Brennan Klein\n",
            "Brian Uzzi\n",
            "Briony Swire-Thompson\n",
            "Brooke Foucault Welles\n",
            "Bruno Lepri\n",
            "Byungkyu Lee\n",
            "Calvin Yixiang Cheng\n",
            "Cameron Lai\n",
            "Carolina Coimbra Vieira\n",
            "Cassandra Overney\n",
            "Ceren Budak\n",
            "Chloe Ahn\n",
            "Chris Callison-Burch\n",
            "Christoph Benedikt Gote\n",
            "Christopher Danforth\n",
            "Claudia Acciai\n",
            "Cristian E Candia\n",
            "Damian Serwata\n",
            "Dan Jurafsky\n",
            "Daniel A. McFarland\n",
            "Daniel Larremore\n",
            "Daniel Matter\n",
            "Daniel Romero\n",
            "Daniele Quercia\n",
            "Dashun Wang\n",
            "David Garcia\n",
            "David Joachim Grüning\n",
            "David Jurgens\n",
            "David Lagnado\n",
            "David Rand\n",
            "David Rothschild\n",
            "Deb Roy\n",
            "Dilrukshi Gamage\n",
            "Doug Beeferman\n",
            "Douglas Richard Guilbeault\n",
            "Drew Dimmery\n",
            "Duncan J. Watts\n",
            "Eaman Jahani\n",
            "Ebru Sanliturk\n",
            "Edward Lee\n",
            "Elisabeth Stockinger\n",
            "Emilio Zagheni\n",
            "Emma Spiro\n",
            "Esteban Moro\n",
            "Fabian Baumann\n",
            "Fabio Carrella\n",
            "Federico Zimmerman\n",
            "Felix Schmidt\n",
            "Fengyuan Michael Liu\n",
            "Filipi Nascimento Silva\n",
            "Filippo Menczer\n",
            "Francesco Pierri\n",
            "Francisco Barreras\n",
            "Frank Schweitzer\n",
            "Frederik Riedel\n",
            "Fujio Toriumi\n",
            "Gabriella Harari\n",
            "Genki Ichinose\n",
            "Giona Casiraghi\n",
            "Giuseppe Russo\n",
            "Gordon Pennycook\n",
            "Gülşah Akçakır\n",
            "Haewoon Kwak\n",
            "Hang Jiang\n",
            "Haoning Xue\n",
            "Hause Lin\n",
            "Homa Hosseinmardi\n",
            "Hope Schroeder\n",
            "Hugo Subtil\n",
            "Hyejin Youn\n",
            "Ichiro Sakata\n",
            "Indraneel Mane\n",
            "Inho Hong\n",
            "Isabella Loaiza\n",
            "Isabelle Langrock\n",
            "Ivan Smirnov\n",
            "Ivano Bison\n",
            "Iyad Rahwan\n",
            "Jad Kabbara\n",
            "Jake M. Hofman\n",
            "James Calum Young\n",
            "James Evans\n",
            "Jana Lasser\n",
            "Jason Burton\n",
            "Jennifer Pan\n",
            "Jingwen Zhang\n",
            "Jinhyuk Yun\n",
            "Jisun An\n",
            "John Bryden\n",
            "Jon Kleinberg\n",
            "Jonathan St-Onge\n",
            "Josephine Lukito\n",
            "Joshua Garland\n",
            "Julia Koltai\n",
            "Juniper L Lovato\n",
            "Junsol Kim\n",
            "Jürgen Pfeffer\n",
            "Kai-Cheng Yang\n",
            "Karim Hamade\n",
            "Katie Spoon\n",
            "Kazutoshi Sasahara\n",
            "Kevin Munger\n",
            "Kimitaka Asatani\n",
            "Kiran Garimella\n",
            "Kokil Jaidka\n",
            "Kristina Gligoric\n",
            "Kumar Chandra\n",
            "Laura Boeschoten\n",
            "Laura Maria Alessandretti\n",
            "Layla Bouzoubaa\n",
            "Levin Brinkmann\n",
            "Likun Cao\n",
            "Lillio Mok\n",
            "Linnea Gandhi\n",
            "Luca Maria Aiello\n",
            "Luca Pappalardo\n",
            "Luca Rossi\n",
            "Luca Verginer\n",
            "Lucio La Cava\n",
            "Luigi Arminio\n",
            "Lyle Ungar\n",
            "Mahnaz Roshanaei\n",
            "Makoto Mizuno\n",
            "Manoel Horta Ribeiro\n",
            "Marco Tonin\n",
            "Mareike Wieland\n",
            "Marie-Laure Charpignon\n",
            "Markus Strohmaier\n",
            "Martin Gerlach\n",
            "Martin Hilbert\n",
            "Massimiliano Luca\n",
            "Mateusz Nurek\n",
            "Mathias Wullum Nielsen\n",
            "Matteo Magnani\n",
            "Matthew DeVerna\n",
            "Matthew Edwards\n",
            "Mattia Samory\n",
            "Max Pellert\n",
            "Maximilian Schich\n",
            "Michael Geers\n",
            "Michele Tizzoni\n",
            "Milena Tsvetkova\n",
            "Mirta Galesic\n",
            "Mitsuo Yoshida\n",
            "Mohammed Alsobay\n",
            "Mohsen Bahrami\n",
            "Morgan Ryan Frank\n",
            "Munjung Kim\n",
            "Márton Rakovics\n",
            "Nabeel Gillani\n",
            "Nail Furkan Bashan\n",
            "Neil Fasching\n",
            "Niccolo Pescetelli\n",
            "Nicholas LaBerge\n",
            "Nicolò Alessandro Girardini\n",
            "Noshir Contractor\n",
            "Ozgur Can Seckin\n",
            "Patrick Gildersleve\n",
            "Pedro Ramaciotti Morales\n",
            "Peter Dodds\n",
            "Peter Meylakhs\n",
            "Petter Holme\n",
            "Philipp Lorenz-Spreen\n",
            "Piotr Bródka\n",
            "Piotr Sapiezynski\n",
            "Priyanka Goonetilleke\n",
            "Pu Yan\n",
            "Qi Wang\n",
            "Qiankun Zhong\n",
            "Qing Ke\n",
            "Qiusi Sun\n",
            "Rachith Aiyappa\n",
            "Radosław Michalski\n",
            "Ralph Schroeder\n",
            "Reid McIlroy-Young\n",
            "Renzhe Yu\n",
            "Riccardo Gallotti\n",
            "Robert West\n",
            "Roberta Sinatra\n",
            "Roman Kyrychenko\n",
            "Ronald E. Robertson\n",
            "Ryan Whalen\n",
            "Sadamori Kojaku\n",
            "Sagar Kumar\n",
            "Salvatore Giorgi\n",
            "Sam Zhang\n",
            "Samar Haider\n",
            "Samuel Fraiberger\n",
            "Sanja Scepanovic\n",
            "Sanjay Kairam\n",
            "Santo Fortunato\n",
            "Sara Bonati\n",
            "Saumya Tripathi\n",
            "Scott A. Hale\n",
            "Sebastian Stier\n",
            "Sebastiano Bontorin\n",
            "Segun Aroyehun\n",
            "Shadi Rezapour\n",
            "Shahan Ali Memon\n",
            "Sharad Goel\n",
            "Sharath Chandra Guntuku\n",
            "Shelby Grossman\n",
            "Shreya Havaldar\n",
            "Siddhartha Sen\n",
            "Simone Centellegher\n",
            "Sky CH-Wang\n",
            "Sourav Medya\n",
            "Stefan Herzog\n",
            "Stephan Lewandowsky\n",
            "Subhayan Mukerjee\n",
            "Sumer Vaid\n",
            "Sune Lehmann\n",
            "Sunny Rai\n",
            "Taekho You\n",
            "Taha Yasseri\n",
            "Taichi Murayama\n",
            "Taizo Horikomi\n",
            "Takahiro Yabe\n",
            "Takayuki Mizuno\n",
            "Talal Rahwan\n",
            "Tara Sowrirajan\n",
            "Tenzin Tamang\n",
            "Tessa Masis\n",
            "Thomas Franz Müller\n",
            "Tian Yang\n",
            "Tim Faverjon\n",
            "Tiziano Piccardi\n",
            "Tobias Felix Werner\n",
            "Tobin South\n",
            "Tom Theile\n",
            "Trisevgeni Papakonstantinou\n",
            "Valerii Chirkov\n",
            "Vedran Sekara\n",
            "Veniamin Veselovsky\n",
            "Woo-Sung Jung\n",
            "Xinlan Emily Hu\n",
            "Yilang Peng\n",
            "Yong-Yeol Ahn\n",
            "Yoshi Meke Bird\n",
            "Zhen Xu\n",
            "Zhuangyuan Fan\n",
            "Ziv Epstein\n",
            "Zoltan Kmetty\n",
            "Zsófia Rakovics\n",
            "The results have been saved to a text file: /content/drive/MyDrive/IC2S2_Common_names.txt\n"
          ]
        }
      ]
    }
  ]
}